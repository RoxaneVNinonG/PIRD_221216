{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d410e39-e0d4-4430-ba0f-fc8c59d620d0",
   "metadata": {},
   "source": [
    "# Code Python - ELECTRE Tri "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c038ddb9",
   "metadata": {},
   "source": [
    "## Introduction to the project\n",
    "\n",
    "Multi-criteria Decision Analysis (MCDA) is a decision support protocol for ranking elements by evaluating them on different criteria. It deals with a problem that has several aspects depending on the wishes of a decision maker. MCDA's makes a problem more understandable, transparent, and accessible. MCDA has developed well in environmental management such as renovation problems which are dynamic systems that bring together many actors, many factors with long-term applications and a lot of uncertainty. \n",
    "\n",
    "To take into account the fluctuations of the input data in environmental projects and thus to obtain results less sensitive to variations, this method is coupled with the Monte Carlo principle. Instead of using crisp data, Monte Carlo allows the use of distributions for each of the data and thus allows variations in the data to be incorporated into the analysis. \n",
    "\n",
    "In this technical report, the implementation of this new procedure is presented regarding a case study (Daniel, 2022). A company wanted to find a method to choose an energy refurbishment scenario for a group of three buildings located in the Lyon region, in France.  The Multi Criteria Decision Analysis used is ELECTRE Tri. The mechanisms used and the input data are presented first. Then, the different steps of the new procedures are described one by one. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c329d900",
   "metadata": {},
   "source": [
    "## ELECTRE Tri\n",
    "\n",
    "### ELECTRE Tri method\n",
    "\n",
    "ELECTRE Tri is the multi-criteria decision analysis method chosen for the project which aim to sort all the alternatives, i.e. the different possibilities for which there is a choice process, in predefined categories. They correspond to the ranks of the alternatives. These alternatives are evaluated by several criteria, perspectives of evaluations of different natures. In its process, the input data including criteria weights and performance matrix is compared to reference profiles i.e. the limits, for each criterion, of the categories. From these alternative/profile comparisons, preference relations are determined, indicating how an alternative relates to a profile. This method results in an optimistic and pessimistic sorting of the alternatives according to the direction of classification. \n",
    "\n",
    "In this method, the input data and parameters used are : \n",
    "- Alternatives: options from which the decision-maker must choose\n",
    "- Criteria: Perspectives on which the alternatives are evaluated, quantitative or qualitative\n",
    "- Weight: Degree of importance of each criterion in \\%. \n",
    "- Performance Matrix: Matrix with the performance of each alternatives regarding each criterion\n",
    "- Reference profiles: Values that define the different performance boundaries for each criterion\n",
    "- Thresholds: Boundaries, defined by decision-makers, to measure the indifference or the preference between an alternative and a reference profile, or the very bad performance of an alternative compared to a profile.  \n",
    "\n",
    "\n",
    "First of all, ELECTRE Tri is a multicriteria decision-making process that begins by comparing alternatives to profiles, which enables the classification of alternatives into specific categories. This method allows for the independent comparison of alternatives, without the ranking of one alternative being influenced by the ranking of others (Corrente, 2016). Thus, it not only identifies the alternatives that best meet the decision-makers' requirements, but also provides an overall performance assessment of each alternative. \n",
    "\n",
    "Also, a specificty of ELECTRE Tri is that criteria are given weights. Criteria are then established hierarchically, which allows some criteria to be performed with greater interest than others (Corrente, 2016). The method can include numerous criteria which corresponds well to complex issues such as environmental problems. Finally, This method includes thresholds, values which defined the objectives of the decision makers. This is crucial in an environmental decision-making process, since it prevents a very poor performance in one criterion from being compensated by a very good performance in another criterion. \n",
    "\n",
    "In all its aspects, the ELECTRE Tri multi-criteria decision analysis method appeared interesting to develop and use in the framework of environmental projects. Here are the different steps of calculation of ELECTRE Tri that will be followed during this notebook :\n",
    "- Partial concordance $C_j(a_i,b_k)$ and $C_j(b_k,a_i)$ : for each criterion $j$, each alternative $a_i$ is compared to each reference profile $b_k$ to determine if it is consistent with the statement \"$a_i$ is at least as good as $b_k$\"\n",
    "- Discordance $D_j(a_i,b_k)$ and $D_j(b_k,a_i)$ : for each criterion $j$, each alternative $a_i$ is compared to each reference profile $b_k$ to determine if it is discordant with the statement \"$a_i$ is at least as good as $b_k$\"\n",
    "- Global concordance $C(a_i,b_k)$ and $C(b_k,a_i)$: the partial concordance values calculated for each criterion $j$ are aggregated to obtain a global concordance per alternative $a_i$ and reference profile $b_k$ pair.\n",
    "- Degree of credibility $\\delta(a_i,b_k)$ and $\\delta(b_k,a_i)$ : the degree of credibility is the global concordance weakened by the eventual veto effects that can be found in the discordance\n",
    "- Over-ranking relations : thanks to the credibility degrees computed previously, the preference relations between each alternative $a_i$ and each reference profile $b_k$ are determined \n",
    "- Pessimistic and optimistic ranking : rank each alternative $a_i$ in a category\n",
    "\n",
    "In the first 4 calculation steps: concordance, discordance, global concordance and degree of credibility, the calculations will be made twice. The analysis is carried out by comparing alternatives to profiles and profiles to alternatives in order to have a precise notion of the distance between the two. As explained in Figure 1, the performance of an alternative to a profile does not indicate a performance of a profile to an alternative. \n",
    " \n",
    "<center>\n",
    "<figure>\n",
    "  <img src=\"drawbacks.png\" width=\"50%\" height=\"50%\">\n",
    "  <figcaption><i> Figure 1: Schema of the comparison of an alternative with a reference profile</i></figcaption>\n",
    "</figure>\n",
    "</center>\n",
    "\n",
    "\n",
    "### ELECTRE Tri applied to the renovation decision making process\n",
    "\n",
    "#### Input data\n",
    "\n",
    "The input data correspond to all the data collected by the technicians in order to establish the method. These data are collected from decision-makers and consultancy firms. \n",
    "\n",
    "##### Criteria $g$\n",
    "\n",
    "According to Roy B. (Roy, 1985), a criterion is a \"tool\" that allows to evaluate an action by a specific \"point of view\". Since these criteria will allow us to establish preference relations between many alternatives, it quality of construction is crucial. Also it is important that all the actors adhere to the choice of criteria and understand what each criterion represents, its precise definition and its evaluation method. Criteria should be diversified, precise but not redundant to avoid assessing the same element twice. Thus, the assessment methods for each of the criteria should be precisely described so that the same data is not used to assess different criteria. Each criterion is defined by it unit and it weight. A criterion can have a direction of preference that can be either increasing or decreasing.\n",
    "\n",
    "\n",
    "*In order to cover all aspects of the project, 4 categories of criteria are defined: economic, social, technical and environmental where several criteria are formulated. For this project, a total of 16 criteria are finally used.*\n",
    "\n",
    "##### Alternatives $a$\n",
    "\n",
    "The alternatives are the different possible outcomes of the choice process. In this project, the method should show which type of renovation best fits the building and the decision makers's objectives. In order to make the method undestandable, the actions to be compared represent the different renovation possibilities that exist, named as scenarios of renovation. The method gives the performance of each scenario regarding the others. \n",
    "\n",
    "The energy renovation of a building affects several areas and in each of these areas there are several possibilities. Thus renovation scenarios are formed with coherent elementary actions. Families of alternatives are formed according to the different possible alternatives in each field.\n",
    "\n",
    "*In the project, seven areas have been identified. For each of these areas, different alternatives are developed to obtain a total of 24 basic renovation actions. From the elementary actions, Thus, 28 renovation solutions are identified in total with 7 groups, first renovation solution being the one where no changes are made. In the data file, the alternatives are named $S$.*\n",
    "\n",
    "\n",
    "##### Performance Matrix \n",
    " \n",
    "Each alternative is evaluated regarding each criterion previously established. The evaluation of the performance $a$ of the alternative $i$ regarding the criterion $j$ will be noted $u_j(a_i)$. In the performance matrix, each column corresponds to an alternative and each line to a criterion.\n",
    "\n",
    "In a case of a criterion with an increasing preference direction, the higher the evaluation of the alternative on this criterion $u_j(a_i)$, the better the alternative performs on this criterion. Conversely, for a criterion with a decreasing performance direction, the lower the evaluation of the alternative on this criterion $u_j(a_i)$, the lower the performance of this alternative on this criterion. \n",
    "\n",
    "In order to unify the calculations and not to have to differentiate between the two cases described above, the performance values in criteria with a decreasing preference direction will be multiplied by \"-1\". Thus, these criteria will also get an increasing performance direction. \n",
    "\n",
    "*To sum up, in this project 28 alternatives, renovation scenarios, will be evaluated thanks to 16 criteria.* \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e1b6ddbb",
   "metadata": {},
   "source": [
    "#### Parameters\n",
    "\n",
    "Parameters are the data involved in the method. They are values defined by the decision makers and the technician. \n",
    "\n",
    "##### Reference profiles $b$\n",
    "The alternatives are not compared with each other but to reference profiles. Reference profiles can be seen as boundary reference actions that allows to define the upper and lower bounds of each category (Almeida-Dias et. al, 2010). As represented in the Figure 2, these reference profiles are specific to each criterion. All the profiles for all the criteria form the categories. \n",
    "\n",
    "<center>\n",
    "<figure>\n",
    "  <img src=\"ref_profiles2.png\" width=\"50%\" height=\"50%\">\n",
    "  <figcaption><i> Figure 2: Reference profiles </i></figcaption>\n",
    "</figure>\n",
    "</center>\n",
    "\n",
    "In order to have these boundaries for all the categories, if $q$ is the number of categories, there is $q$ reference profiles starting from zero ($q+1$ reference profile in total). \n",
    "As for the performances, the values of the reference profiles with a decreasing preference direction are multiplied by \"-1\" in order to obtain only criteria with increasing preference direction. \n",
    "\n",
    "##### Thresholds $q$, $p$, $v$\n",
    "\n",
    "Thresholds are parameters that quantify the difference between the alternatives and the reference profiles in order to determine whether this difference is indifferent or significant. Indeed, the difference between the alternatives and the reference profiles will be calculated and compared to these thresholds. In this objective, three thresholds are necessary:\n",
    "- The indifference threshold $q$ : indicates whether the alternative is equivalent to the reference profile\n",
    "- The preference threshold $p$ : indicates wehther the alternative or the profile is preferred\n",
    "- The veto threshold $v$ : indicates whether the difference is too high to be acceptable. \n",
    "\n",
    "These 3 thresholds are determined for each criterion $j$, going from 1 to $n$. Thresholds are thus noted for each criterion $j$: indifference threshold: $q_j$, preference threshold, $p_j$ and veto threshold $v_j$.\n",
    "\n",
    "##### Cut-off threshold $\\lambda $\n",
    "\n",
    "The cut-off threshold is a value between 0 and 1 that defines the desired level of requirement. The closer the value is to 1, the higher the level of requirement is chosen, the closer it is to 0 the lower the level of requirement. The default value used in the ELECTRE Tri method is 0.75, but it can be adapted according to the case studied. To choose the right cut-off threshold, the desired precision in ranking the alternatives, the goals to be achieved, and the constraints of the problem should be considered. \n",
    "\n",
    "In the ELECTRE Tri method, the alternatives are compared to reference profiles, it is necessary to establish the relation between the two. The details of this step are described in the \"Outranking relations\" part. At the beginning of this step, the \"degree of credibility\" describing the proximity between each alternative and each reference profile is compared to the cut-off threshold. It determines if a preference of the alternative compared to the reference profile can be established or not.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fde24ef1",
   "metadata": {},
   "source": [
    "## Uncertainty on the performances\n",
    "\n",
    "The process of filling in the performance matrix is often complicated. It is necessary to find the values for each alternative for each criterion. This value is a fixed number representing the performance of the alternative against a criterion. However, this is not representative of reality; the values are actually subject to fluctuations. This is due to two factors: uncertainty and variability of the data. Uncertainty reflects the fact that measurements are subject to random errors and systematic errors caused by biases or systematic deviations in the measurement process, which can introduce variations in the measured values (Faber, 2005). The variability represents the fluctuation due to kinematic, kinetic and spatio-temporal effect (Chau et. al, 2005).\n",
    "\n",
    "In order to obtain more robust data, another parameter is integrated into the method, **the uncertainty of the data**. Instead of applying the method to a data table, the method is applied to a distribution table. These data fluctuations are not represented in the performance matrix data, however, if they were included, they would have significant consequences for the rest of the ELECTRE Tri process.\n",
    "\n",
    "The uncertainty is introduced through two main elements:\n",
    "- Representation of data as Probability Density Functions (PDFs), as opposed to crisp values. \n",
    "- The Monte Carlo method, a statistical technique that utilizes random sampling, is applied to these distributions. This method and its implementation will be developed in details later. \n",
    "\n",
    "A probability density function (PDF) is a mathematical expression that describes the probability distribution of a discrete random variable (Kenton, 2022). There are various types of PDFs that can be used to represent the distribution of different types of phenomena, including the uniform, exponential, normal, and Poisson distribution (Harrison, 2010). In the context of the case study, it was decided to use only one type of distribution to represent the entire dataset: the normal distribution.\n",
    "\n",
    "The normal distribution needs two parameters to be described : \n",
    "- The mean value $ \\mu$\n",
    "- The standard deviation $ \\sigma$\n",
    "\n",
    "The normal distribution is noted $N(\\mu, \\sigma^2)$.\n",
    "*Note that the variance is $v=\\sigma^2$. For this reason, in the rest of the project the calculations will be done with the mean value $ \\mu$ and the variance $v$ as parameters.*\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "482184b9",
   "metadata": {},
   "source": [
    "### Python environment\n",
    "\n",
    "The code is developed with the library Pandas, Numpy and Math. The input data are imported from a csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfcdcf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random, vstack, empty\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f512a50",
   "metadata": {},
   "source": [
    "### Import of data from csv file as a Pandas Dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2d03a3f",
   "metadata": {},
   "source": [
    "The input of the whole analysis is a `csv.file` made of 16 lines and 39 columns.\n",
    "\n",
    "The 16 lines correponds to 16 criteria defined earlier. \n",
    "The indices of the lines are therefore the names of the criteria: <br>\n",
    "`g1.1, g1.2, g1.3, g1.4, g1.5, g2.1, g2.2, g2.3, g2.4, g3.1, g3.2, g3.3, g3.4, g4.1, g4.2, g4.3, g4.4, g5.1, g5.2, g5.3`.\n",
    "\n",
    "The columns contain the following informations : \n",
    "- The **mean value of the performance** of each scenario regarding each criterion (columns 0 to 27) <br>\n",
    "Names of the columns : `'S1.1','S1.2','S1.3','S1.4','S2.1','S2.2','S2.3','S2.4','S3.1','S3.2','S3.3','S3.4','S4.1',`\n",
    "`'S4.2','S4.3','S4.4','S5.1','S5.2','S5.3','S5.4','S6.1','S6.2','S6.3','S6.4','S7.1','S7.2',`\n",
    "`'S7.3','S7.4'`\n",
    "- The **weight** of each criterion (column 28) <br>\n",
    "Name of the column : `Weights`\n",
    "- The **variance** of each criterion (column 29) <br>\n",
    "Name of the column : `Var`\n",
    "- The **6 reference profiles** : $b0, b1, b2, b3, b4$ and $b5$ (columns 30 to 35) <br>\n",
    "Names of the columns : `b0`, `b1`,`b2`, `b3`, `b4` and `b5`\n",
    "- The **3 thresholds** : $q$ (the indifference threshold), $p$ (the preference threshold), $v$ (the veto threshold) (columns 36 to 38) <br>\n",
    "Names of the columns : `q`, `p` and `v`\n",
    "\n",
    "\n",
    "It is imported as a dataframe `d`.<br>\n",
    "Two others parameters are also defined : \n",
    "- `λ` : the **cut-off threshold**\n",
    "- `repetition` : the **number of repetition** of the ELECTRE Tri method desired\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f6003b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('Input_data.csv')\n",
    "λ = 0.75\n",
    "repetition = 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e703acc6",
   "metadata": {},
   "source": [
    "### Monte Carlo Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "126e492b",
   "metadata": {},
   "source": [
    "#### How does it works ###\n",
    "Our hypothesis is to use the **Monte Carlo method** to obtain data sets from distributions and use those data sets in the ELECTRE Tri procedure. \n",
    "\n",
    "Monte-Carlo simulation is used in complex systems in order to estimate some operations by using random sample and statistical modeling. \n",
    "1. Pick a value from Probability Density Functions\n",
    "2. Run the calculation multiple times: ELECTRE Tri in our case\n",
    "3. Obtain a set of results to be analyzed \n",
    "\n",
    "The first step involve to be given Probability Distribution Functions as inputs. For our study, all the values will be represented as normal distributions. To describe these distributions 2 parameters are needed : \n",
    "- the mean value : `m` given per scenario $S$ and per criterion $g$\n",
    "- the variance : `variance` given per criterion $g$\n",
    "\n",
    "These values are given in the `d` DataFrame given as input of the code. \n",
    "\n",
    "The following function allows to :\n",
    "1. Creates the Normal Distribution from the input data present in `data`\n",
    "2. Pick a random value in each of it\n",
    "3. Return a DataFrame called `ndata` with the random values picked \n",
    "\n",
    "*The DataFrame returned will also contain all the parameters initially present in the `data` DataFrame.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e73a5cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MC(data):\n",
    "    \"\"\"\n",
    "    Build a new performance matrix from the distribution\n",
    "    with m : mean value and v : variance per criterion\n",
    "    :param data: Data Frame with input data and parameters\n",
    "    :return: ndata: Data frame with the new performance Data Frame with random value picked\n",
    "     in the distribution\n",
    "    \"\"\"\n",
    "    ndata = data.copy()\n",
    "    variance = ndata['VAR'].values  # general variance located in the column \"VAR\"\n",
    "    m = ndata.iloc[:, 0:28].values  # for each scenario : columns 0 to 27\n",
    "    v = np.abs(m * variance[:, np.newaxis])  # variance v of the performance matrix\n",
    "    perf = np.random.normal(m, v)  # random value in the normal distribution\n",
    "    ndata.iloc[:, 0:28] = perf\n",
    "    return ndata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "590af63e",
   "metadata": {},
   "source": [
    "### Partial concordance\n",
    "\n",
    "The partial concordance refers to the degree of concordance, i.e. agreement between the evaluations of pairs of alternatives and reference profiles. In other words, it evaluates how well each option performs relative to the others with respect to the set of criteria. \n",
    "\n",
    "This function takes as input the `data` DataFrame containing all the performances as well as all the others parameters and input of the method, but only the performances, the reference profiles, and the thresholds will be used.\n",
    "\n",
    "The objective is to calculate, regarding each criterion $j$ the concordance between each pair of alternative $a_i$ and reference profiles $b_k$ i.e. the alternatives regarding the profiles and the profiles regarding the alternatives: \n",
    "- The concordance $C_j(a_i,b_k)$\n",
    "- The concordance $C_j(b_k,a_i)$ <br>\n",
    "*for $i$ the scenarios, $k$ the reference profiles and $j$ the criteria*\n",
    "\n",
    "The Figure 3 shows how the value of the corcordance $C_j(a_i,b_k)$ is determined:\n",
    "\n",
    "<center>\n",
    "<figure>\n",
    "  <img src=\"conc2.png\" width=\"70%\" height=\"70%\">\n",
    "  <figcaption><i> Figure 3: Partial Concordance </i></figcaption>\n",
    "</figure>\n",
    "</center>\n",
    "\n",
    "*with : <br>*\n",
    "- *$u_j(a_i)$ : value of the performance of the scenario $i$ in the criterion $j$*\n",
    "- *$u_j(b_k)$ : value of the reference profile $k$ in the criterion $j$*\n",
    "\n",
    "\n",
    "It can be therefore interpreted as follow : <br>\n",
    " The difference between the performance of an alternative $u_j(a_i)$ and the performance of a reference profile $u_j(b_k)$ regarding the criterion $j$ is calculated. This difference is then compared to the two thresholds $q_j, p_j$, respectively the indifference threshold and the preference threshold. \n",
    "- if $u_j(a_i)-u_j(b_k) > -q_j$    <br>\n",
    "$C_j(a_i,b_k)=1$, the alternative is as good as the profile. \n",
    "- if $u_j(a_i)-u_j(b_k) < -p_j $ <br>\n",
    "$C_j(a_i,b_k)=0$, the alternative $a_i$ is not as good as the profile $b_k$ for the criterion $j$. \n",
    "- if $-p_j < u_j(a_i)-u_j(b_k) < -q_j$   <br>\n",
    " It not possible to neither agree nor disagree with the statement \"the alternative is as good as the profile\", so an intermediate value between 0 and 1 which qualifies the degree of agreement is calulated. The closer it is to 1 the more it agrees with the assumption, the closer it is to 0, the less it agrees with the assumption. \n",
    "\n",
    "Thus, in this case, the two types of concordance can be calculated in the function as follow: <br>\n",
    "<center>\n",
    "\n",
    "$C_j(a_i,b_k) = u_j(a_i)-u_j(b_j)+p_j/(p_j-q_j)$<br>\n",
    "\n",
    "</center>\n",
    "\n",
    "*with : <br>*\n",
    "- *$u_j(a_i)$ : value of the performance of the scenario $i$ in the criterion $j$*\n",
    "- *$u_j(b_k)$ : value of the reference profile $k$ in the criterion $j$*\n",
    "- *$p_j$ : the preference threshold of the criterion $j$* \n",
    "- *$q_j$ : the indiference threshold of the criterion $j$*\n",
    "\n",
    "If the value of the concordance is higher than one it is replaced by `1`, and if it is smaller than zero it is replaced by `0`. \n",
    "\n",
    "The calculattions are done in the same way for the concordance $C_j(b_k,a_i)$. \n",
    "\n",
    "Finally, the function returns two DataFrames : \n",
    "- `new_df` : The concordance between the performances of the alternatives and the reference profiles $C_j(a_i,b_k)$\n",
    "- `new_df2` : The concordance between the performances of the reference profiles and the alternatives $C_j(b_j,a_k)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b2d4985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conc(data):\n",
    "    \"\"\"\n",
    "    Calculates the concordance coefficient between a performance and a profile\n",
    "\n",
    "    :param data: new performance Data Frame and original parameters\n",
    "    :return: new_df: DataFrame with concordance Cj(ai,bk) of each alternative ai\n",
    "    regarding each profile bk for each criterion j\n",
    "    :return: new_df2: DataFrame with concordance Cj(bk,ai) of each profile bk\n",
    "    regarding each alternative ai for each criterion j\n",
    "    \"\"\"\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df2 = pd.DataFrame()\n",
    "    for sc in data.iloc[:, 0:28]:  # for each scenario : columns 0 to 27\n",
    "        for pr in data.iloc[:, 30:36]:  # for each reference profile : columns 30 to 35\n",
    "            alpha = (data[sc] - data[pr] + data[data.columns[37]]) \\\n",
    "                    / (data[data.columns[37]] - data[data.columns[36]])\n",
    "            beta = (data[pr] - data[sc] + data[data.columns[37]]) \\\n",
    "                   / (data[data.columns[37]] - data[data.columns[36]])\n",
    "            new_df = pd.concat([new_df, alpha], axis=1, ignore_index=True)\n",
    "            new_df2 = pd.concat([new_df2, beta], axis=1, ignore_index=True)\n",
    "    new_df[new_df < 0] = 0\n",
    "    new_df[new_df > 1] = 1\n",
    "    new_df2[new_df2 < 0] = 0\n",
    "    new_df2[new_df2 > 1] = 1\n",
    "    return new_df, new_df2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b4c1f41",
   "metadata": {},
   "source": [
    "### Discordance\n",
    "\n",
    "The discordance matrix is a matrix that is used to represent the degree of discordance between pairs of alternatives and reference profiles. It is typically constructed by comparing the values of each alternative on each criterion, and determining whether the difference between the values is significant enough to cause discordance. In contrast to calculating the concordance with the sentence, the discordance with the sentence is studied, i.e. how far apart the alternative and the profile are. \n",
    "\n",
    "This function takes as input the `data` DataFrame containig all the performances as well as all the others parameters and input of the method. In this function, only the performances, the reference profiles, and the thresholds will be used.\n",
    "\n",
    "The objective is to calculate, regarding each criterion $j$, the discordance between each pair of alternative $a_i$ and reference profiles $b_k$ and in both ways: \n",
    "- The discordance $D_j(a_i,b_k)$\n",
    "- The discordance $D_j(b_k,a_i)$ <br>\n",
    "*for $i$ the scenarios, $k$ the reference profiles and $j$ the criteria*\n",
    "\n",
    "The Figure 4 shows how the value of the discordance $D_j(a_i,b_k)$ is determined: \n",
    "\n",
    "<center>\n",
    "<figure>\n",
    "  <img src=\"disc.png\" width=\"70%\" height=\"70%\">\n",
    "  <figcaption><i> Figure 4: Discordance </i></figcaption>\n",
    "</figure>\n",
    "</center>\n",
    "\n",
    "It can be interpreted as follow : <br>\n",
    "The difference between the performance of an alternative $u_j(a_i)$ and the performance of a reference profile $u_j(b_k)$ regarding the criterion $j$ is calculated. This difference is then compared to the two thresholds $p_j, v_j$, respectively the preference threshold and the veto threshold. \n",
    "- if $u_j(a_i)-u_j(b_k) < -p_j$    <br>\n",
    "$D_j(a_i,b_k)=0$, the alternative is as good as the profile $b_k$ for the criterion $j$.\n",
    "- if $u_j(a_i)-u_j(b_k) > -v_j $ <br>\n",
    "$D_j(a_i,b_k)=1$, the alternative $a_i$ is not \"as good as the profile\" $b_k$ for the criterion $j$. \n",
    "- if $-v_j < u_j(a_i)-u_j(b_k) < -p_j$<br>\n",
    " It not possible to establish neither the discordance or not with the statement \"the alternative is as good as the profile\", so an intermediate value between 0 and 1 which qualifies the degree of disagreement is calulated. The closer it is to 1 the more it is discordant with the assumption, the closer it is to 0, the less it is discrodant with the assumption. \n",
    "\n",
    "Thus, in this case, the two types of discordance can be calculated in the function as follow: <br>\n",
    "<center>\n",
    "\n",
    "$D_j(a_i,b_k) = u_j(b_k)-u_j(a_i)-p_j/(v_j-p_j)$<br>\n",
    "\n",
    "</center>\n",
    "\n",
    "*with : <br>*\n",
    "- *$u_j(a_i)$ : value of the performance of the scenario $i$ in the criterion $j$*\n",
    "- *$u_j(b_k)$ : value of the reference profile $k$ in the criterion $j$*\n",
    "- *$p_j$ : the preference threshold of the criterion $j$* \n",
    "- *$v_j$ : the veto threshold of the criterion $j$*\n",
    "\n",
    "If the value is higher than one it is replaced by `1`, and if it is smaller dans zero it is replaced by `0`. \n",
    "\n",
    "The calculations are done the same way for the discordance $D_j(b_k,a_i)$.\n",
    "\n",
    "The function takes as input the `d` Dataframe.\n",
    "Finally, the function returns two DataFrames : \n",
    "- `new_df` : The discordance between the performances of the alternatives and the reference profiles $D_j(a_i,b_k)$\n",
    "- `new_df2` : The discordance between the performances of the reference profiles and the alternatives $D_j(b_k,a_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "414dda50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disco(data):\n",
    "    \"\"\"\n",
    "    Calculates the discordance coefficient between a performance and a profile\n",
    "\n",
    "    :param data: new performance Data Frame and original parameters\n",
    "    :return: new_df: DataFrame with discordance Dj(ai,bk) of each alternative ai\n",
    "    regarding each profile bk for each criterion j\n",
    "    :return: new_df2: DataFrame with discordance Dj(bk,ai) of each profile bk\n",
    "    regarding each alternative ai for each criterion j\n",
    "    \"\"\"\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df2 = pd.DataFrame()\n",
    "    for sc in data.iloc[:, 0:28]:  # for each scenario : columns 0 to 27\n",
    "        for pr in data.iloc[:, 30:36]:  # for each reference profile : columns 30 to 35\n",
    "            alpha = (data[pr] - data[sc] - data[data.columns[37]]) / (\n",
    "                    data[data.columns[38]] - data[data.columns[37]])\n",
    "            beta = (data[sc] - data[pr] - data[data.columns[37]]) / (\n",
    "                    data[data.columns[38]] - data[data.columns[37]])\n",
    "            new_df = pd.concat([new_df, alpha], axis=1, ignore_index=True)\n",
    "            new_df2 = pd.concat([new_df2, beta], axis=1, ignore_index=True)\n",
    "    new_df[new_df < 0] = 0\n",
    "    new_df[new_df > 1] = 1\n",
    "    new_df2[new_df2 < 0] = 0\n",
    "    new_df2[new_df2 > 1] = 1\n",
    "    return new_df, new_df2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e896ce2d",
   "metadata": {},
   "source": [
    "### Global concordance\n",
    "\n",
    "The aim of this step is to calculate the global concordance of each scenario regarding all the criteria. The partial concordance values calculated for each criterion $j$ is aggregated to obtain one unique value of global concordance per per of alternative $a_i$ and reference profile $b_k$. In other words, it expresses to which extend the performance of the alternative $a_i$ with $i$ the scenario and the performance of the profile $b_k$, with $k$ the profile number regarding all the criteria are concordant with the assertion ”$a_i$ outranks $b_k$\". <br>\n",
    "\n",
    "As previously, the calculation are made twice: \n",
    "- $C(a_i,b_k)$: for the alternatives $a_i$ regarding the profiles $b_k$ \n",
    "- $C(b_k,a_i)$: for the profiles $b_k$ regarding the alternatives $a_i$\n",
    "\n",
    "For each case, the following global concordance is calculated regarding each scenario: \n",
    "\n",
    "<center>\n",
    "\n",
    "$C(a_i,b_k) = \\frac {\\sum_{j} C_j(a_i,b_k)  w_j}{\\sum_{j} w_j}$\n",
    "\n",
    "$C(b_k,a_i) = \\frac {\\sum_{j} C_j(b_k,a_i)  w_j}{\\sum_{j} w_j}$\n",
    "\n",
    "</center>\n",
    "\n",
    "*with i the alternative, j the criteria and k the reference profile*\n",
    "\n",
    "\n",
    "The function takes as input  :\n",
    "- Weights of each criterion, located in the `data` DataFrame, in the column 28 named `Weights`\n",
    "- Partial Concordance Matrix: `dconc1`\n",
    "\n",
    "The DataFrame `new_df` returns the Global Concordance for each alternative or for each profile. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5f4a9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gconc(data, dconc1):\n",
    "    \"\"\"\n",
    "    Calculates the global concordance\n",
    "\n",
    "    :param data: new performance Data Frame and original parameters\n",
    "    :param dconc1: concordance Data Frame\n",
    "    :return: new_df: global concordance Data Frame\n",
    "    \"\"\"\n",
    "    new_df = pd.DataFrame(index=['b0', 'b1', 'b2', 'b3', 'b4', 'b5'],\n",
    "                          columns=['S1.1', 'S1.2', 'S1.3', 'S1.4',\n",
    "                                   'S2.1', 'S2.2', 'S2.3', 'S2.4',\n",
    "                                   'S3.1', 'S3.2', 'S3.3', 'S3.4',\n",
    "                                   'S4.1', 'S4.2', 'S4.3', 'S4.4',\n",
    "                                   'S5.1', 'S5.2', 'S5.3', 'S5.4',\n",
    "                                   'S6.1', 'S6.2', 'S6.3', 'S6.4',\n",
    "                                   'S7.1', 'S7.2', 'S7.3', 'S7.4'])\n",
    "    i = 0\n",
    "    for j in range(0, len(dconc1.columns), 6):  # for each scenario : one line out of 6\n",
    "        # C(ai,bk) for the scenario for each reference profile\n",
    "        a = sum(dconc1[j] * data[data.columns[28]]) / sum(data[data.columns[28]])\n",
    "        b = sum(dconc1[j + 1] * data[data.columns[28]]) / sum(data[data.columns[28]])\n",
    "        c = sum(dconc1[j + 2] * data[data.columns[28]]) / sum(data[data.columns[28]])\n",
    "        dr = sum(dconc1[j + 3] * data[data.columns[28]]) / sum(data[data.columns[28]])\n",
    "        e = sum(dconc1[j + 4] * data[data.columns[28]]) / sum(data[data.columns[28]])\n",
    "        f = sum(dconc1[j + 5] * data[data.columns[28]]) / sum(data[data.columns[28]])\n",
    "        th = [a, b, c, dr, e, f]\n",
    "        new_df[new_df.columns[i]] = th  # add the global concordance as a new column\n",
    "        i = i + 1\n",
    "    return new_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85cec1c2",
   "metadata": {},
   "source": [
    "### Degree of credibility"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4f31262",
   "metadata": {},
   "source": [
    "The degree of credibility evaluates if the assumption that a scenario outperforms a profile is plausible and to which extent \"$a_i$ outranks $b_k$\", resulting in a value between 0 (the assumption is not plausible) and 1 (the assumption is very plausible). The calculation are made twice, once for the alternatives in relation to the profiles and once for the profiles in relation to the alternatives.  The degree of credibility evaluating the outranking of the alternative $a_i$ over the reference profile $b_k$ is noted : $ \\delta(a_i,b_k)$ and conversely the degree of credibility evaluating the outranking of the reference profile $b_k$ over the alternative $a_i$ is noted $ \\delta(b_k,a_i)$.\n",
    "\n",
    "The degree of credibility is calculated thanks to :\n",
    "- the Global Concordance: `dgconc`\n",
    "- the Discordance Matrix: `ddsic` \n",
    "\n",
    "The objective is, for each alternatives, to follow these steps : \n",
    "\n",
    "If, for all the criteria $j$, the discordance is lower or equal to the global concordance : $D_j(a_i,b_k) \\le C(a_i,b_k)$ or respectively $D_j(b_k,a_i) \\le C(b_k,a_i)$, the credibility is equal to the global concordance:\n",
    "<center>\n",
    "\n",
    "$ \\delta(a_i,b_k) = C(a_i,b_k) $\n",
    "\n",
    "$ \\delta(b_k,a_i) = C(b_k,a_i) $\n",
    "\n",
    "</center>\n",
    "\n",
    "Else, if at least one of the discordance is higher than the global concordance, the credibility is calculated as follow : \n",
    "\n",
    "<center>\n",
    "\n",
    "$ \\delta(a_i,b_k) = C(a_i,b_k) * \\prod_{j \\in J } \\frac{(1-D_j(a_i,b_k))}{(1-C(a_i,b_k))} $\n",
    "\n",
    "$ \\delta(b_k,a_i) = C(b_k,a_i) * \\prod_{j \\in J } \\frac{(1-D_j(b_k,a_i))}{(1-C(b_k,a_i))} $\n",
    "\n",
    "</center>\n",
    "\n",
    "*With :*\n",
    "- *J : all the criteria for whom the discordance is lower than the concordance : $D_j(a_i,b_k) \\ge C(a_i,b_k)$ or respectively $D_j(b_k,a_i) \\le C(b_k,a_i)$*\n",
    "- *$C(a_i,b_k)$ : the global concordance of the alternative $a_i$ with the reference profile $b_k$* \n",
    "- *$C(b_k,a_i)$ : the global concordance of the reference profile $b_k$ with the alternative $a_i$*\n",
    "- *$D(a_i,b_k)$ : the global discordance of the alternative $a_i$ with the reference profile $b_k$*\n",
    "- *$D(b_k,a_i)$ : the global discordance of the reference profile $b_k$ with the alternative $a_i$*\n",
    "\n",
    "In order to better understand the steps of this calculation the degree of credibility is calculated as follows: \n",
    "-  If within the criteria, none of them is discordant, the degree of credibility is equal to the global concordance :\n",
    "<center>\n",
    "\n",
    "$ \\delta(a_i,b_k) = C(a_i,b_k) $ or $ \\delta(b_k,a_i) = C(b_k,a_i) $\n",
    "\n",
    "</center>\n",
    "\n",
    "- If one of them is discordant (equal to one), that means that it is above the veto threshold, the degree of credibility is equal to zero. The degree of credibility is the global concordance weakened by the eventual veto effects that can be found in the partial discordance : \n",
    "<center>\n",
    "\n",
    "$ \\delta(a_i,b_k) = 0$ or $ \\delta(b_k,a_i) = 0$\n",
    "\n",
    "</center>\n",
    "\n",
    "- Finally, if some criteria are lower than $1$ but higher that the concordance, the degree of credibility is lowered by these effects, the calculation is therefore developed in the formula above.\n",
    "\n",
    "The function return `dcred` Data Frame which is the credibility degrees calculated from `dgconc` and `ddisc`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d1d2f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def credibility(dgconc, ddisc):\n",
    "    \"\"\"\n",
    "    Calculates the credibility degree\n",
    "\n",
    "    :param dgconc: Global concordance Data Frame\n",
    "    :param ddisc: Discordance Data Frame\n",
    "    :return: dcred: Credibility degree Data Frame\n",
    "    \"\"\"\n",
    "    # initialization\n",
    "    dcred = pd.DataFrame(index=['b0', 'b1', 'b2', 'b3', 'b4', 'b5'],\n",
    "                         columns=['S1.1', 'S1.2', 'S1.3', 'S1.4',\n",
    "                                  'S2.1', 'S2.2', 'S2.3', 'S2.4',\n",
    "                                  'S3.1', 'S3.2', 'S3.3', 'S3.4',\n",
    "                                  'S4.1', 'S4.2', 'S4.3', 'S4.4',\n",
    "                                  'S5.1', 'S5.2', 'S5.3', 'S5.4',\n",
    "                                  'S6.1', 'S6.2', 'S6.3', 'S6.4',\n",
    "                                  'S7.1', 'S7.2', 'S7.3', 'S7.4'])\n",
    "    for j in range(0, len(ddisc.columns), 6):\n",
    "        sc = int(j / 6)\n",
    "        degree = [0, 0, 0, 0, 0, 0]\n",
    "        for pr in range(len(dcred.index)):\n",
    "            # verification if all Dj < C\n",
    "            verif = sum(ddisc[j + pr][c] > dgconc[dgconc.columns[sc]][pr]\n",
    "                        for c in ddisc.index)\n",
    "            # case 1\n",
    "            if verif == 0:\n",
    "                degree[pr] = dgconc[dgconc.columns[sc]][pr]\n",
    "            # case 2\n",
    "            else:\n",
    "                degree[pr] = (((1 - ddisc[j + pr][ddisc[j + pr]\n",
    "                                                  > dgconc[dgconc.columns[sc]][pr]])\n",
    "                               / (1 - dgconc[dgconc.columns[sc]][pr])).prod()) * dgconc[dgconc.columns[sc]][pr]\n",
    "        dcred[dcred.columns[sc]] = degree\n",
    "    return dcred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54e0adca",
   "metadata": {},
   "source": [
    "### Over-ranking\n",
    "\n",
    "The objective of this step is to establish preference relations between the alternatives $a$ and the reference profiles $b$. \n",
    "These relations are established thanks to the degree of credibility determined just before and thanks to the cut-off threshold $\\lambda$.  \n",
    "\n",
    "There are 4 types of relations that can be established between each $a_i$ and each $b_k$\n",
    "- $a_i$  `I`  $b_k$ : $a_i$  is Indifferent to  $b_k$ \n",
    "- $a_i$  `>`  $b_k$ : $a_i$  is preferred to  $b_k$ \n",
    "- $a_i$  `<`  $b_k$ : $a_i$  is not preferred to  $b_k$ \n",
    "- $a_i$  `R`  $b_k$ : $a_i$  incomparable to $b_k$ \n",
    "\n",
    "These relations are represented in the Figure 5. \n",
    "\n",
    "<center>\n",
    "<figure>\n",
    "  <img src=\"overrank2.png\" width=\"50%\" height=\"50%\">\n",
    "  <figcaption>Figure 5: Preference relations</figcaption>\n",
    "</figure>\n",
    "</center>\n",
    "\n",
    "This is how these relations are determined : \n",
    "\n",
    "\n",
    "\n",
    "- if $\\delta(a_i,b_k) > \\lambda$ and $\\delta(b_k,a_i) > \\lambda$ <br>\n",
    "    $a_i$ I $b_k$ : $a_i$  is Indifferent to  $b_k$ \n",
    "- if $\\delta(a_i,b_k) > \\lambda$ and $\\delta(b_k,a_i) < \\lambda$ <br>\n",
    "     $a_i > b_k$ : $a_i$  is preferred to  $b_k$\n",
    "- if $\\delta(a_i,b_k) < \\lambda$ and $\\delta(b_k,a_i) > \\lambda$ <br>\n",
    "    $a_i < b_k$ : $a_i$  is not preferred to  $b_k$\n",
    "- if $\\delta(a_i,b_k) < \\lambda$ and $\\delta(b_k,a_i) < \\lambda$ <br>\n",
    "    $a_i$  R  $b_k$ : $a_i$  incomparable to $b_k$ \n",
    "\n",
    "The input data of the function are :\n",
    "- The credibility degrees of the alternatives in relation to the profiles: `cred1`\n",
    "- The credibility degrees of the profiles in relation to the alternatives: `cred2`\n",
    "- The cut-off threshold: `param`\n",
    "\n",
    "The function returns a single Dataframe `new_df` containing all these relations between the alternatives and the profiles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59cd031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_ranking_relations(cred1, cred2, param):\n",
    "    \"\"\"\n",
    "    Calculates the relations between each alternative and each profile\n",
    "\n",
    "    :param cred1: Credibility degree Data Frame of the alternatives regarding\n",
    "    each profile\n",
    "    :param cred2: Credibility degree Data Frame of the profiles regarding\n",
    "    each alternative\n",
    "    :param param: Cut-off threshold\n",
    "    :return: new_df: Data Frame with the relation of each alternative regarding\n",
    "    each profile\n",
    "    \"\"\"\n",
    "    # initialization\n",
    "    new_df = pd.DataFrame(index=['b0', 'b1', 'b2', 'b3', 'b4', 'b5'],\n",
    "                          columns=['S1.1', 'S1.2', 'S1.3', 'S1.4',\n",
    "                                   'S2.1', 'S2.2', 'S2.3', 'S2.4',\n",
    "                                   'S3.1', 'S3.2', 'S3.3', 'S3.4',\n",
    "                                   'S4.1', 'S4.2', 'S4.3', 'S4.4',\n",
    "                                   'S5.1', 'S5.2', 'S5.3', 'S5.4',\n",
    "                                   'S6.1', 'S6.2', 'S6.3', 'S6.4',\n",
    "                                   'S7.1', 'S7.2', 'S7.3', 'S7.4'])\n",
    "    classementa = cred1.apply(lambda x: x - param)\n",
    "    classementb = cred2.apply(lambda x: x - param)\n",
    "    # 1 if outperform (S), 0 if not\n",
    "    classementa[classementa > 0] = 1\n",
    "    classementa[classementa < 0] = 0\n",
    "    classementb[classementb > 0] = 1\n",
    "    classementb[classementb < 0] = 0\n",
    "    mask = (classementa == classementb) & (classementa == 1)\n",
    "    new_df = new_df.mask(mask, \"I\")\n",
    "    mask = (classementa == classementb) & (classementa == 0)\n",
    "    new_df = new_df.mask(mask, \"R\")\n",
    "    mask = (classementb != 0) & (classementa == 0)\n",
    "    new_df = new_df.mask(mask, \"<\")\n",
    "    mask = (classementa != 0) & (classementb == 0)\n",
    "    new_df = new_df.mask(mask, \">\")\n",
    "    return new_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbc76eca",
   "metadata": {},
   "source": [
    "## Sorting\n",
    "\n",
    "The relations previously established allow to reach the final goal of the method, i.e. to assign to each alternative a category. \n",
    "Two sorting procedures are performed: optimistic and pessimistic sorting. The major difference between the two is that the pessimistic sort \"pushes the alternative down\" starting from the best category, while the optimistic sort \"pushes the alternative up\" starting from the worst category. \n",
    "\n",
    "A median ranking can be obtained as an average of these two rankings."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07cc33b8",
   "metadata": {},
   "source": [
    "### Pessimistic sorting\n",
    "\n",
    "The following function permits to obtain the pessimistic sorting thanks to the over-ranking relations we just established. The objective is to place each scenario in one of the 5 predefined categories. This type of sorting \"pushes the action down\". \n",
    "\n",
    "This is how the ranking works : <br>\n",
    "\n",
    "The 6 reference profiles $b0, b1, b2, b3, b4$ and $b5$ delineate 5 categories : <br>\n",
    "$C1, C2, C3, C4$ and $C5$, C5 being the best one and C1 the worse as shown in the Figure 6. \n",
    "\n",
    "<center>\n",
    "<figure>\n",
    "  <img src=\"pessi_sort.jpg\" width=\"10%\" height=\"10%\">\n",
    "  <figcaption> <i> Figure 6: Pessimistic sorting </figcaption>\n",
    "</figure>\n",
    "</center>\n",
    "\n",
    "</i>\n",
    "\n",
    "For each scenario, these categories are browsed from the best to the worst ( from C5 to C1 ). \n",
    "For each reference profile encountered the credibility $ \\delta(a_i,b_k)$ are compared to the cutting threshold $\\lambda$ : \n",
    "- if $ \\delta(a_i,b_k) > \\lambda $ : the alternative is ranked in the category with the same number as $b_k$\n",
    "- if $ \\delta(a_i,b_k) < \\lambda $ : it continues to the next reference profile \n",
    "\n",
    "This function takes as input: \n",
    "- The relations between the alternatives and the profiles: `ranking`\n",
    "- The memory of the ranking of the alternatives in the categories: `mpessi`\n",
    "\n",
    "It returns the updating of the Data Frame `mpessi` with the ranking obtained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c83fa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pessimistic_sort(ranking, mpessi):\n",
    "    \"\"\"\n",
    "    Builds the pessimistic sorting\n",
    "\n",
    "    :param ranking: Data Frame with the relation of each alternative regarding\n",
    "    each profile\n",
    "    :param mpessi: Data Frame storing the pessimist ranking of each alternative\n",
    "    :return: mpessi: Updates of the Data Frame storing the pessismist sorting\n",
    "    of alternatives\n",
    "    \"\"\"\n",
    "    for sc in ranking:\n",
    "        step = mpessi[sc]\n",
    "        for pr in reversed(range(len(ranking.index))):\n",
    "            if ranking[sc][pr] == '>' or ranking[sc][pr] == 'I':\n",
    "                step[step.index[pr]] = step[step.index[pr]] + 1  # classified\n",
    "                break\n",
    "        mpessi[sc] = step\n",
    "    return mpessi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4da92d51",
   "metadata": {},
   "source": [
    "### Optimistic sorting\n",
    "\n",
    "The following function permits to obtain the optimistic ranking thanks to the over-ranking relations established.\n",
    "\n",
    "The ranking works as follow: <br>\n",
    "\n",
    "As previously 6 reference profiles delineate 5 categories, C5 being the best one and C1 the worse as shown in the Figure 7. \n",
    "\n",
    "<center>\n",
    "<figure>\n",
    "  <img src=\"opti_sort.jpg\" width=\"10%\" height=\"10%\">\n",
    "  <figcaption><i> Figure 7: Optimistic sorting</figcaption>\n",
    "</figure>\n",
    "</center>\n",
    "\n",
    "</i>\n",
    "\n",
    "The difference is that for this ranking, for each scenario, these categories are browsed from the worst to the best ( from C1 to C5 ). \n",
    "For each reference profile encountered the over-ranking relation are analyzed : \n",
    "- if $a_i$ `<` $b_k$ : the scenario is ranked in the category with the same number as $b_k$\n",
    "- if $a_i$ `>` $b_k$, $a_i$ `R` $b_k$ or $a_i$ `I` $b_k$ : it continues to the next reference profile \n",
    "\n",
    "This function takes as inputs: \n",
    "- The relations between the alternatives and the profiles: `ranking`\n",
    "- The memory of the ranking of the alternatives in the categories: `mopti`\n",
    "\n",
    "It returns the updating of the Data Frame `mopti` with the ranking obtained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11e6b275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimistic_sort(ranking, mopti):\n",
    "    \"\"\"\n",
    "        Builds the optimistic sorting\n",
    "\n",
    "        :param ranking: Data Frame with the relation of each alternative regarding\n",
    "        each profile\n",
    "        :param mopti: Data Frame storing the optimistic sorting of each alternative\n",
    "        :return: mopti: Updates of the Data Frame storing the optimistic sorting\n",
    "        of alternatives\n",
    "        \"\"\"\n",
    "    for sc in ranking:\n",
    "        step = mopti[sc]\n",
    "        for pr in (range(len(ranking.index))):\n",
    "            if ranking[sc][pr] == '<' or ranking[sc][pr] == 'R':\n",
    "                step[step.index[pr]] = step[step.index[pr]] + 1  # classified\n",
    "                break\n",
    "        mopti[sc] = step\n",
    "    return mopti"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f273c69b",
   "metadata": {},
   "source": [
    "### ELECTRE Tri application function\n",
    "This final method permits to run all the previous methods in order to compute all the steps of the ELECTRE Tri method. \n",
    "\n",
    "First of all, it takes as input : \n",
    "- `data` : the input Dataframe containing the performances, the weights, the variances, the reference profiles and the thresholds\n",
    "- `rep` : the number of times the Electre Tri method will be run, defined at the beginning of the code\n",
    "\n",
    "It creates two data frames :\n",
    "- `pessi_sort` : it allows to keep in memory the pessimistic ranking obtained at each iteration of the method\n",
    "- `opti_sort` : it allows to keep in memory the optimistic ranking obtained at each iteration of the method\n",
    "\n",
    "They are both build in the same way : <br>\n",
    "They are made of 5 lines (corresponding to the 5 categories) and 28 columns (corresponding to the 28 alternatives).\n",
    "Here are the `index` names : <br>\n",
    "`'C1', 'C2', 'C3', 'C4', 'C5'` <br>\n",
    "Here are the `columns` names : <br>\n",
    "`'S1.1','S1.2','S1.3','S1.4','S2.1','S2.2','S2.3','S2.4','S3.1','S3.2','S3.3','S3.4','S4.1',`\n",
    "`'S4.2','S4.3','S4.4','S5.1','S5.2','S5.3','S5.4','S6.1','S6.2','S6.3','S6.4','S7.1','S7.2',`\n",
    "`'S7.3','S7.4'` <br>\n",
    "Initially, they are composed only of zeros .\n",
    "\n",
    "Thereafter the following functions will be executed one after the other, the number of times `rep` which was defined at the very beginning of the code : <br>\n",
    "*(note that the functions below are clearly defined and explained one by one right above their code,including detailed explanations of input and output data)*\n",
    "\n",
    "- `MCarlo` : Monte Carlo function <br>\n",
    "    Takes as input : the input dataframe `d`<br>\n",
    "    Return : the dataframe `newdata` : the mean values have been replaced by the performances  <br>\n",
    "- `conce` : Partial Concordance function <br>\n",
    "    Takes as input :  the input dataframe `newdata` <br>\n",
    "    Return : the two concordance matrix `dconca, dconcb` <br>\n",
    "- `disco` : Discordance function <br>\n",
    "    Takes as input : the input dataframe `newdata` <br>\n",
    "    Return : the two discordance dataframes `ddisca, ddiscb`<br>\n",
    "- `global_conc` : Global Concordance function <br>\n",
    "    This function is called twice : \n",
    "    - Once taking in input : the input dataframe `newdata` and the concordance dataframe `dconca` <br>\n",
    "        Return : the global concordance dataframe `dgconca`\n",
    "    - Once taking in input : the input dataframe `newdata` and the concordance dataframe `dconcb` <br>\n",
    "        Return : the global concordance dataframe`dgconcb`\n",
    "- `credibility` : Credibility Degree function <br>\n",
    "    This function is called twice : \n",
    "    - Once taking in input : the global concordance and discordance dataframes `dgconca` and `ddisca`<br>\n",
    "        Return : credibility dataframe `dcreda`\n",
    "    - Once taking in input : the global concordance and discordance dataframes `dgconcb` and `ddiscb`<br>\n",
    "        Return : credibility dataframe `dcredb`\n",
    "- `over_ranking_relations` : Over-ranking function <br>\n",
    "    Takes as input : the two credibility dataframes `dcreda` and `dcredb`<br>\n",
    "    Return : the overanking dataframe `dranking` <br>\n",
    "- `optimistic_sort` : Optimistic sorting function <br>\n",
    "    Takes as input : the overanking datadrame `dranking` and the optimistic sorting dataframe obtained at the previous iteration `opti_sort` <br>\n",
    "    Return : the optimistic sorting daframe modified, i.e. with the optimistic sorting added to the previous `opti_sort`\n",
    "- `pessimistic_sort`: Pessimistic sorting function <br>\n",
    "    Takes as input : the overanking datadrame `dranking` and the pessimistic sorting dataframe `pessi_sort` <br>\n",
    "    Return : the pessimistic sorting daframe modified, i.e. with the pessimistic sorting added to the previous `pessi_sort`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd90570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Elec_tri(data, rep):\n",
    "    \"\"\"\n",
    "    Function which capitalises ELECTRE_Tri calculations and repeats them\n",
    "     a rep number of times\n",
    "\n",
    "    :param data: Input data and parameters\n",
    "    :param rep: Number of repetition\n",
    "    :return: opti_sort: Data Frame with percentage of time each alternative are classified in each\n",
    "    category within a optimistic sorting\n",
    "    :return: pessi_sort: Data Frame with percentage of time each alternative are classified in each\n",
    "     category within a pessimistic sorting\n",
    "    \"\"\"\n",
    "    pessi = np.zeros((5, 28))\n",
    "    opti = np.zeros((5, 28))\n",
    "    pessi_sort = pd.DataFrame(pessi, index=['C1', 'C2', 'C3', 'C4', 'C5'],\n",
    "                              columns=['S1.1', 'S1.2', 'S1.3', 'S1.4',\n",
    "                                       'S2.1', 'S2.2', 'S2.3', 'S2.4',\n",
    "                                       'S3.1', 'S3.2', 'S3.3', 'S3.4',\n",
    "                                       'S4.1', 'S4.2', 'S4.3', 'S4.4',\n",
    "                                       'S5.1', 'S5.2', 'S5.3', 'S5.4',\n",
    "                                       'S6.1', 'S6.2', 'S6.3', 'S6.4',\n",
    "                                       'S7.1', 'S7.2', 'S7.3', 'S7.4'])\n",
    "    opti_sort = pd.DataFrame(opti, index=['C1', 'C2', 'C3', 'C4', 'C5'],\n",
    "                             columns=['S1.1', 'S1.2', 'S1.3', 'S1.4',\n",
    "                                      'S2.1', 'S2.2', 'S2.3', 'S2.4',\n",
    "                                      'S3.1', 'S3.2', 'S3.3', 'S3.4',\n",
    "                                      'S4.1', 'S4.2', 'S4.3', 'S4.4',\n",
    "                                      'S5.1', 'S5.2', 'S5.3', 'S5.4',\n",
    "                                      'S6.1', 'S6.2', 'S6.3', 'S6.4',\n",
    "                                      'S7.1', 'S7.2', 'S7.3', 'S7.4'])\n",
    "    # repetitions\n",
    "    for i in range(rep):\n",
    "        newdata = MC(data)\n",
    "        dconca, dconcb = conc(newdata)\n",
    "        ddisca, ddiscb = disco(newdata)\n",
    "        dgconca = gconc(newdata, dconca)\n",
    "        dgconcb = gconc(newdata, dconcb)\n",
    "        dcreda = credibility(dgconca, ddisca)\n",
    "        dcredb = credibility(dgconcb, ddiscb)\n",
    "        dranking = over_ranking_relations(dcreda, dcredb, λ)\n",
    "        opti_sort = optimistic_sort(dranking, opti_sort)\n",
    "        pessi_sort = pessimistic_sort(dranking, pessi_sort)\n",
    "    pessi_sort = pessi_sort.apply(lambda x: (x / rep) * 100)  # %\n",
    "    opti_sort = opti_sort.apply(lambda x: x / rep * 100)  # %\n",
    "    return opti_sort, pessi_sort"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6baf0cb",
   "metadata": {},
   "source": [
    "The `electre_tri` function is run returning two DataFrames : `o_sorting` and `p_sorting`. \n",
    "\n",
    "Then two csv files are created containing the repartition of the scenarios in the categories as percentages : \n",
    "- `pessimistic_sorting.csv` for the pessimistic sorting \n",
    "- `optimistic_sorting.csv` for the optimistic sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84b6b1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "o_sorting, p_sorting = Elec_tri(d, repetition)\n",
    "o_sorting_transposed = o_sorting.transpose()\n",
    "o_sorting_transposed['Total'] = 100\n",
    "p_sorting_transposed = p_sorting.transpose()\n",
    "p_sorting_transposed['Total'] = 100\n",
    "\n",
    "# p_sorting.to_csv('pessimistic_sorting.csv')\n",
    "# o_sorting.to_csv('optimistic_sorting.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6bf6e371",
   "metadata": {},
   "source": [
    "### Printing of the optimistic sorting\n",
    "\n",
    "The optimistic ranking is printed. Each column corresponds to a category (from `C1` to `C5`). The last column `Total` correspond to the sum of the percentages of the line. \n",
    "Each line corresponds to an alternative, from `S1.1` to `S7.4`.\n",
    "\n",
    "The results are given as percentage: for each alternative it gives the proportion of times it was classified in each category. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3f57cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimistic sorting of the scenarios is:\n",
      "       C1     C2     C3     C4    C5  Total\n",
      "S1.1  0.0  100.0    0.0    0.0   0.0    100\n",
      "S1.2  0.0   30.0   70.0    0.0   0.0    100\n",
      "S1.3  0.0    0.0   90.0   10.0   0.0    100\n",
      "S1.4  0.0   40.0   60.0    0.0   0.0    100\n",
      "S2.1  0.0   20.0   70.0   10.0   0.0    100\n",
      "S2.2  0.0    0.0    0.0   70.0  30.0    100\n",
      "S2.3  0.0    0.0   20.0   80.0   0.0    100\n",
      "S2.4  0.0    0.0   10.0   70.0  20.0    100\n",
      "S3.1  0.0   10.0   90.0    0.0   0.0    100\n",
      "S3.2  0.0    0.0    0.0  100.0   0.0    100\n",
      "S3.3  0.0   20.0   20.0   60.0   0.0    100\n",
      "S3.4  0.0    0.0   10.0   90.0   0.0    100\n",
      "S4.1  0.0    0.0  100.0    0.0   0.0    100\n",
      "S4.2  0.0    0.0  100.0    0.0   0.0    100\n",
      "S4.3  0.0   30.0   70.0    0.0   0.0    100\n",
      "S4.4  0.0    0.0  100.0    0.0   0.0    100\n",
      "S5.1  0.0  100.0    0.0    0.0   0.0    100\n",
      "S5.2  0.0  100.0    0.0    0.0   0.0    100\n",
      "S5.3  0.0  100.0    0.0    0.0   0.0    100\n",
      "S5.4  0.0  100.0    0.0    0.0   0.0    100\n",
      "S6.1  0.0    0.0   20.0   80.0   0.0    100\n",
      "S6.2  0.0    0.0    0.0  100.0   0.0    100\n",
      "S6.3  0.0   20.0   80.0    0.0   0.0    100\n",
      "S6.4  0.0    0.0   10.0   80.0  10.0    100\n",
      "S7.1  0.0  100.0    0.0    0.0   0.0    100\n",
      "S7.2  0.0  100.0    0.0    0.0   0.0    100\n",
      "S7.3  0.0  100.0    0.0    0.0   0.0    100\n",
      "S7.4  0.0  100.0    0.0    0.0   0.0    100\n"
     ]
    }
   ],
   "source": [
    "print(\"The optimistic sorting of the scenarios is:\")\n",
    "print(o_sorting_transposed)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fce525aa",
   "metadata": {},
   "source": [
    "### Printing of the pessimistic sorting\n",
    "\n",
    "The pessimistic ranking is printed. Each column corresponds to a category (from `C1` to `C5`). Each line corresponds to an alternative, from `S1.1` to `S7.4`. The last column `Total` correspond to the sum of the percentages of the line. \n",
    "\n",
    "The results are given as percentage: for each alternative it gives the proportion of times it was classified in each category. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e5c6061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pessimistic sorting of the scenarios is:\n",
      "         C1     C2     C3    C4   C5  Total\n",
      "S1.1  100.0    0.0    0.0   0.0  0.0    100\n",
      "S1.2   30.0   70.0    0.0   0.0  0.0    100\n",
      "S1.3    0.0   90.0   10.0   0.0  0.0    100\n",
      "S1.4   40.0   60.0    0.0   0.0  0.0    100\n",
      "S2.1   20.0   70.0   10.0   0.0  0.0    100\n",
      "S2.2    0.0    0.0   70.0  30.0  0.0    100\n",
      "S2.3    0.0   20.0   80.0   0.0  0.0    100\n",
      "S2.4    0.0   10.0   70.0  20.0  0.0    100\n",
      "S3.1   10.0   90.0    0.0   0.0  0.0    100\n",
      "S3.2    0.0    0.0  100.0   0.0  0.0    100\n",
      "S3.3   20.0   20.0   60.0   0.0  0.0    100\n",
      "S3.4    0.0   10.0   90.0   0.0  0.0    100\n",
      "S4.1    0.0  100.0    0.0   0.0  0.0    100\n",
      "S4.2    0.0  100.0    0.0   0.0  0.0    100\n",
      "S4.3   30.0   70.0    0.0   0.0  0.0    100\n",
      "S4.4    0.0  100.0    0.0   0.0  0.0    100\n",
      "S5.1  100.0    0.0    0.0   0.0  0.0    100\n",
      "S5.2  100.0    0.0    0.0   0.0  0.0    100\n",
      "S5.3  100.0    0.0    0.0   0.0  0.0    100\n",
      "S5.4  100.0    0.0    0.0   0.0  0.0    100\n",
      "S6.1    0.0   20.0   80.0   0.0  0.0    100\n",
      "S6.2    0.0    0.0  100.0   0.0  0.0    100\n",
      "S6.3   20.0   80.0    0.0   0.0  0.0    100\n",
      "S6.4    0.0   10.0   80.0  10.0  0.0    100\n",
      "S7.1  100.0    0.0    0.0   0.0  0.0    100\n",
      "S7.2  100.0    0.0    0.0   0.0  0.0    100\n",
      "S7.3  100.0    0.0    0.0   0.0  0.0    100\n",
      "S7.4  100.0    0.0    0.0   0.0  0.0    100\n"
     ]
    }
   ],
   "source": [
    "print(\"The pessimistic sorting of the scenarios is:\")\n",
    "print(p_sorting_transposed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f1ca142",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "##### 1. Scenarios are spread in the categories\n",
    "\n",
    "The output obtained is a table with the percentage for each alternatives to be classified in each category. This new representation of the results adds significant information. \n",
    "In the Table 1, the results obtained without the new procedure can be compared to the one just obtained above with the code. This was applied to the case study, and the focus is made on the optimistic sorting on the four scenarios : 'S2.1', 'S2.2', 'S2.3' and 'S2.4'. This analysis is also valid for the other scenarios and for the pessimistic ranking.\n",
    "\n",
    "<center>\n",
    "<figure>\n",
    "  <img src=\"analysis1.png\" width=\"35%\" height=\"35%\">\n",
    "  <figcaption><i> Table 1: Optimistic ranking obtained without the new procedure for 4 scenarios<i></figcaption>\n",
    "</figure>\n",
    "</center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b871d9f9",
   "metadata": {},
   "source": [
    "This gives major information on the scenarios. Firstly, the **results are more nuanced**, which makes it easier to compare the alternatives. Indeed, by focusing on scenario `S2.1`, it can be observed that in the classic ELECTRE Tri method, it is classified in category 3. The new procedure shows that by integrating the fluctuation of the data, this scenario is indeed classified the majority of the time in category 3 but is also classified in category 2 and 4 (see Optimistic ranking above). This provides information on the possibility of ranking alternatives in the face of uncertainty and variance. Between two alternatives that seem equivalent in ranking, the percentage of ranking in other categories allows to differentiate them. When looking at two scenarios that are initially classified in the same category, `S2.2` and `S2.4` in category 4, it is difficult to distinguish between them with this information alone. Thanks to the integration of fluctuation, these two scenarios are also classified in categories 2, 3 and 5. However, the scenario `S2.2` is more often classified in category 5 than the scenario. These results can therefore lead to believe that the `S2.2` scenario performs better than the `S2.4` scenario and therefore **allows the decision makers to separate two alternatives that at first seemed equal**. \n",
    "\n",
    "This allocation allows for a more **specific study of elementary actions**. The alternatives are cleverly constructed to observe the impact of elementary actions on rankings. This added information makes it possible to observe more precisely whether or not an elementary action improves the overall performance of an alternative.  \n",
    "As an exemple, it is possible to have a look at the results obtained for the 4 following scenarios: S2.1, S2.2, S3.1, S3.2. All Group 2 scenarios have an electric radiant panel and existing electric floor and all Group 3 scenarios have electric storage heating without electric floor heating. Otherwise, these two families of scenarios are built the same with the index 2 scenarios diverging from the index 1 scenarios by solar panels on the roof. The index 1 scenarios are not provided with any autonomous energy system. By analysing the results obtained previsouly, it is easily observable that the scenarios including solar panels are better categorised. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ab65614",
   "metadata": {},
   "source": [
    "##### 2. Impact of the variance\n",
    "\n",
    "Alternatives do not respond uniformly to the distributions applied by criteria. Some alternatives can\n",
    "be classified in 4 different categories while some of them are always classified in only 1 category. If we look at the\n",
    "scenarios of family 2 : `S2.1`, `S2.2`, `S2.3` and `S2.4`, and family 7 :  `S7.1`, `S7.2`, `S7.3` and `S7.4`: \n",
    "\n",
    "Both families of scenarios were exposed to fluctuations with similar standard deviations. However, it is noteworthy that the scenarios of family 2 can be classified into four distinct categories based on their fluctuation values, while the scenarios of family 7 are consistently classified in the same category. This discrepancy in classification is influenced by various factors, including the proximity of the alternatives’ performance to the established thresholds. Even a minor deviation in the data can cause the threshold to be exceeded, resulting in a different classification. Furthermore, the weight assigned toeach criterion being evaluated also plays a role, as a variation in performance for a criterion with a high weight is more likely to affect the overall results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ffa75b4",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "The proposed new procedure adds a significant amount of information by providing the percentage of ranking for each alternative within each category, which allows for a more detailed differentiation of alternatives. This method also facilitates the comparison of alternatives that were previously ranked at the same level, thereby providing a more precise examination of the performance of individual actions within scenarios. To fully leverage the benefits of this method, it is crucial for decision-makers to have a solid understanding of the process, including how different data and parameters affect the results.\n",
    "\n",
    "Furthermore, this procedure can be effectively combined with other multi-criteria analysis methods to ensure that no important information is overlooked, since they use the same performance matrix to group the input data for the analysis process. By generalizing the use of distributions, instead of fixed values, this method allows for a more comprehensive understanding of the sensitivity of the results to the input data and can help identify a wider range of potential outcomes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c4459ed",
   "metadata": {},
   "source": [
    "### Bibliography \n",
    "*Almeida-Dias, J., J.R. Figueira, and B. Roy (2010). “ELECTRE TRI-C: A multiple criteria sorting\n",
    "method based on characteristic reference actions”. In: European Journal of Operational Research.*<br>\n",
    "*Chau, T., S. Young, and S. Redekop (2005). “Managing variability in the summary and comparison of\n",
    "gait data”. In: Journal of NeuroEngineering and Rehabilitation 22.* <br>\n",
    "*Corrente, S., S. Greco, and R. Slowinski (2016). “Multiple Criteria Hierarchy Process for ELECTRE Tri\n",
    "methods”. In: European Journal of Operational Research, 252, pp. 191–203* <br>\n",
    "*Daniel, S. and C. Ghiaus (2022). “Multi-criteria decision analysis of energy retrofit of residential buildings:\n",
    "methodology and feedback from real application”. In: Energies 15* <br>\n",
    "*Faber, M. H. (2005). “On the Treatment of Uncertainties and Probabilities in Engineering Decision\n",
    "Analysis”. In: Journal of Offshore Mechanics and Artic Engeneering 127, pp. 243–248.* <br>\n",
    "*Harrison, R. L. (2010). “Introduction to Monte Carlo Simulation.” In: AIP Conference Proceedings 1204,\n",
    "pp. 17–21.* <br>\n",
    "*Kenton, W. (2022). “The Basics of Probability Density Function (PDF), With an Example.” In: Investo-\n",
    "pedia.*<br>\n",
    "*Roy, B. (1985). “Methodologie Multicritère d’Aide à la Decision.” In: Economica, Paris.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "263930470851f494f0ed2879c35b57985588df20f9e529b86e97dd5eb9ddc466"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

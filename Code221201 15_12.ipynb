{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d410e39-e0d4-4430-ba0f-fc8c59d620d0",
   "metadata": {},
   "source": [
    "# Code Python - Electre Tri "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c038ddb9",
   "metadata": {},
   "source": [
    "## Introduction to the project\n",
    "\n",
    "The company at the origin of the request is the social landlord 3F, part of the national group Action Logement. Its request concerns the renovation of three of its housing buildings located in the Lyon region. These buildings having been built in the years 2014, the company thus considered necessary to carry out renovation works for the whole of these 3 buildings. \n",
    "\n",
    "The company has found it difficult in the past to find out how to renovate a building in view regarding the different aspects that come into play. For example, when looking at the minimum energy loss between primary and final energy, gas appears to be the most interesting form of energy. However, when looking at the environmental impact of this form of energy, gas is badly ranked. Thus, they wish to take into account several aspects of energy renovation in this project.  \n",
    "\n",
    "Since several options of renovation are possible and the decision is based on multiple criteria, it has been chosen that a multi-criteria analysis should be carried out."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c329d900",
   "metadata": {},
   "source": [
    "### Electre Tri as a multi-criteria analysis \n",
    "\n",
    "The Electre Tri method is the multi-criteria analysis that is selected for the project. In its process, the input data for each item is normalised using thresholds and compared to difference profiles that separate categories. This method results in an optimistic and pessimistic ranking of the elements in which every actions are ranked in categories.\n",
    "\n",
    "In our project, 28 scenarios will be compared thanks to 16 criteria.\n",
    "\n",
    "The following code allows to execute step by step the calculations of the Electre Tri method :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfcdcf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random, vstack, empty\n",
    "import math\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f512a50",
   "metadata": {},
   "source": [
    "### Import of data from csv file as a Pandas Dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2d03a3f",
   "metadata": {},
   "source": [
    "The input of the whole analysis is a `csv.file` containing the following informations : \n",
    "- The **mean value of the performance** of each scenario regarding each criteria (columns 0 to 27)\n",
    "- The **weight** of each criteria (column 28)\n",
    "- The **variance** of each criteria (column 29)\n",
    "- The **6 reference profiles** : $b0, b1, b2, b3, b4$ and $b5$ (columns 30 to 35)\n",
    "- The **3 thresholds** : $q$ (the indifference threshold), $p$ (the preference threshold), $v$ (the veto threshold) (columns 36 to 38)\n",
    "\n",
    "It is imported as a dataframe `d`.<br>\n",
    "Two others parameters are also defined : \n",
    "- `λ` : the **cutting threshold**\n",
    "- `repet` : the **number of repetition** of the Electre Tri method desired\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f6003b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('Input_data.csv')\n",
    "λ = 0.75\n",
    "repet = 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e703acc6",
   "metadata": {},
   "source": [
    "### Monte Carlo Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "126e492b",
   "metadata": {},
   "source": [
    "Since we study 28 scenarios according to 16 criteria, compute all the possible combinations of performance values would not be feasible. To have more robust results, our hypothesis is to use the **Monte Carlo method** to obtain data sets from distributions and use those data sets in the Electre Tri procedure. \n",
    "\n",
    "Monte-Carlo simulation is used in complex systems in order to estimate some operations by using random sample and statistical modeling. \n",
    "1. Pick a value from Probability Distribution Functions\n",
    "2. Run the calculation multiple times: Electre Tri in our case\n",
    "3. Obtain a set of results to be analyzed \n",
    "\n",
    "The first step involve to be given Probability Distribution Functions as inputs. For our study, all the values will be represented as normal distributions. To descrive these distributions 2 parameters are needed : \n",
    "- the mean value : `m`\n",
    "- the variance : `variance`\n",
    "\n",
    "These values are given in the `d` DataFrame given as input of the code. \n",
    "\n",
    "The following function allows to :\n",
    "1. Thanks to the variance and mean value for each performance : create the Normal Distribution\n",
    "2. Pick a random value in each of it\n",
    "3. Return a DataFrame also called `d` with the random values picked \n",
    "\n",
    "*The DataFrame returned will also contain all the parameters initially present in the `d` DataFrame.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e73a5cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCarlo(d):\n",
    "    variance = d['VAR'].values\n",
    "    m = d.iloc[:, 0:28].values # for each scenario : columns 0 to 27 \n",
    "    v = np.abs(m * variance[:, np.newaxis]) # calculation of the variance v \n",
    "    perf = np.random.normal(m, v) # pick a random value in th normal distribution with variance : v, mean : m \n",
    "    d.iloc[:, 0:28] = perf \n",
    "    return d\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "590af63e",
   "metadata": {},
   "source": [
    "### Concordance\n",
    "\n",
    "The concordance matrix is a table that compare each pair of alternatives being considered, in our case, the sceanarios. In other words, it evaluates how well each option performs relative to the others with respect to the set of criteria. \n",
    "\n",
    "This function take as input the `d` DataFrame containig all the performances as well as all the others parameters and input of the method, but only the performances, the reference profiles, and the thresholds will be used.\n",
    "\n",
    "The objective is to calculate the concordance between each pair of alternative and reference profiles and in both ways: \n",
    "- The concordance $C_j(a_i,b_k)$\n",
    "- The concordance $C_j(b_k,a_i)$ <br>\n",
    "\n",
    "*for $i$ the scenarios, $k$ the reference profiles and $j$ the criteria*\n",
    "\n",
    "The following schema shows how the value of the corcordance is determined : \n",
    "\n",
    "<center>\n",
    "<figure>\n",
    "  <img src=\"concordance.jpg\" width=\"50%\" height=\"50%\">\n",
    "</figure>\n",
    "</center>\n",
    "\n",
    "*with : <br>*\n",
    "- *$u_j(a_i)$ : value of the performance of the scenario $i$ in the criterion $j$*\n",
    "- *$u_j(b_k)$ : value of the reference profile $k$ in the criterion $j$*\n",
    "\n",
    "Thus, here is how the two types of concordance can be calculated in the function: <br>\n",
    "<center>\n",
    "\n",
    "$C_j(a_i,b_k) = u_j(a_i)-u_j(b_j)+p_j/p_j-q_j$<br>\n",
    "$C_j(b_k,a_i) = u_j(b_j)-u_j(a_i)+p_j/p_j-q_j$<br>\n",
    "\n",
    "</center>\n",
    "\n",
    "\n",
    "If the value is higher than one it is replaced by `1`, and if it is smaller dans zero it is replaced by `0`. \n",
    "\n",
    "Finally, the function returns two DataFrames : \n",
    "- `dconca` : The concordance between the performances and the reference profiles $C_k(a_i,b_j)$\n",
    "- `dconcb` : The concordance between the reference profiles and the performances $C_k(b_j,a_i)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b2d4985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conce(d):\n",
    "    new_df = pd.DataFrame() #DataFrame that will contain Cj(ai,bk)\n",
    "    new_df2 = pd.DataFrame() #DataFrame that will contain Cj(bk,ai)\n",
    "    for sc in d.iloc[:, 0:28]: # for each scenario : columns 0 to 27\n",
    "        for pr in d.iloc[:, 30:36]: # for each reference profile : columns 30 to 35\n",
    "            alpha = (d[sc]-d[pr]+d[d.columns[37]])/(d[d.columns[37]]-d[d.columns[36]]) # Cj(ai,bk) calculation\n",
    "            beta = (d[pr]-d[sc]+d[d.columns[37]])/(d[d.columns[37]]-d[d.columns[36]]) # Cj(bk,ai) calculation\n",
    "            new_df = pd.concat([new_df, alpha], axis=1, ignore_index=True)\n",
    "            new_df2 = pd.concat([new_df2, beta], axis=1, ignore_index=True)\n",
    "    # replace the negative values by zero and the one higher than one by one in both DataFrames\n",
    "    new_df[new_df<0]=0\n",
    "    new_df[new_df>1]=1\n",
    "    new_df2[new_df2<0]=0\n",
    "    new_df2[new_df2>1]=1\n",
    "    return new_df, new_df2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b4c1f41",
   "metadata": {},
   "source": [
    "### Discordance\n",
    "\n",
    "The discordance matrix is a matrix that is used to represent the degree of discordance between pairs of alternatives. It is typically constructed by comparing the values of each alternative on each criterion, and determining whether the difference between the values is significant enough to cause discordance. \n",
    "\n",
    "This function take as input the `d` DataFrame containig all the performances as well as all the others parameters and input of the method, but only the performances, the reference profiles, and the thresholds will be used.\n",
    "\n",
    "The objective is to calculate the discordance between each pair of alternative and reference profiles and in both ways: \n",
    "- The discordance $D_j(a_i,b_k)$\n",
    "- The discordance $D_j(b_k,a_i)$ <br>\n",
    "*for $i$ the scenarios, $k$ the reference profiles and $j$ the criteria*\n",
    "\n",
    "The following schema shows how the value of the discordance is determined : \n",
    "\n",
    "<center>\n",
    "<figure>\n",
    "  <img src=\"discordance.jpg\" width=\"50%\" height=\"50%\">\n",
    "</figure>\n",
    "</center>\n",
    "\n",
    "Thus, here is how the two types of discordance can be calculated in the function: <br>\n",
    "<center>\n",
    "\n",
    "$D_j(a_i,b_k) = u_j(b_k)-u_j(a_i)-p_j/v_j-p_j$<br>\n",
    "$D_j(b_k,a_i) = u_j(a_i)-u_j(b_k)-p_j/v_j-p_j$<br>\n",
    "\n",
    "</center>\n",
    "\n",
    "*with : <br>*\n",
    "- *$u_j(a_i)$ : value of the performance of the scenario $i$ in the criterion $j$*\n",
    "- *$u_j(b_k)$ : value of the reference profile $k$ in the criterion $j$*\n",
    "\n",
    "If the value is higher than one it is replaced by `1`, and if it is smaller dans zero it is replaced by `0`. \n",
    "\n",
    "The function takes as input the `d` Dataframe.\n",
    "Finally, the function returns two DataFrames : \n",
    "- `ddiscoa` : The discordance between the performances and the reference profiles $D_j(a_i,b_k)$\n",
    "- `ddiscob` : The discordance between the reference profiles and the performances $D_j(b_k,a_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "414dda50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disco(d):\n",
    "    new_df = pd.DataFrame() # DataFrame that will contain Dj(ai,bk)\n",
    "    new_df2 = pd.DataFrame() # DataFrame that will contain Dj(bk,ai)\n",
    "    for sc in d.iloc[:, 0:28]:  # for each scenario : columns 0 to 27\n",
    "        for pr in d.iloc[:, 30:36]: # for each reference profile : columns 30 to 35\n",
    "            alpha = (d[sc]-d[pr]+d[d.columns[37]])/(d[d.columns[38]]-d[d.columns[37]]) # Dj(ai,bk) calculation\n",
    "            beta = (d[pr]-d[sc]+d[d.columns[37]])/(d[d.columns[38]]-d[d.columns[37]]) # Dj(bk,ai) calculation\n",
    "            new_df = pd.concat([new_df, alpha], axis=1, ignore_index=True)\n",
    "            new_df2 = pd.concat([new_df2, beta], axis=1, ignore_index=True)\n",
    "     # replace the negative values by zero and the one higher than one by one in both DataFrames\n",
    "    new_df[new_df<0]=0\n",
    "    new_df[new_df>1]=1\n",
    "    new_df2[new_df2<0]=0\n",
    "    new_df2[new_df2>1]=1\n",
    "    return new_df, new_df2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e896ce2d",
   "metadata": {},
   "source": [
    "### Global concordance\n",
    "\n",
    "The function allows to calculate the global concordance of each scenario regarding each threshold. It takes as input the concordance matrix and the weights for each criteria. <br>\n",
    "\n",
    "The function takes as input the weights of each criterion, located in the `d` DataFrame as well as the concordance matrix, separated into 2 DataFrames previously : `dconca` and `dconcb`. \n",
    "\n",
    "The objective is, for each scenario calculate the following global concordance : \n",
    "\n",
    "<center>\n",
    "\n",
    "$C(a_i,b_k) = \\frac {\\sum_{j} C_j(a_i,b_k) * w_j}{\\sum_{j} w_j}$\n",
    "\n",
    "</center>\n",
    "\n",
    "*with i the scenarios, j the criteria and k the reference profiles*\n",
    "\n",
    "This function has to be used twice :\n",
    "- Once taking as input `dconca` and returning as output `dgconca` : $C(a_i,b_k)$\n",
    "- Once taking as input `dconcb` and returning as output `dgconcb` : $C(b_k,a_i)$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5f4a9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_conc(d,dconc1):\n",
    "    new_df = pd.DataFrame(index=['b0', 'b1', 'b2', 'b3', 'b4', 'b5'], columns=['S1.1','S1.2','S1.3','S1.4','S2.1','S2.2','S2.3','S2.4','S3.1','S3.2','S3.3','S3.4','S4.1','S4.2','S4.3','S4.4','S5.1','S5.2','S5.3','S5.4','S6.1','S6.2','S6.3','S6.4','S7.1','S7.2','S7.3','S7.4']) \n",
    "    i = 0\n",
    "    for j in range(0, len(dconc1.columns),6): # for each scenario : one line out of 6 \n",
    "        # C(ai,bk) for the scenario for each reference profile\n",
    "        a = sum(dconc1[j]*d[d.columns[28]])/sum(d[d.columns[28]]) \n",
    "        b = sum(dconc1[j+1]*d[d.columns[28]])/sum(d[d.columns[28]])  \n",
    "        c = sum(dconc1[j+2]*d[d.columns[28]])/sum(d[d.columns[28]]) \n",
    "        dr = sum(dconc1[j+3]*d[d.columns[28]])/sum(d[d.columns[28]])  \n",
    "        e = sum(dconc1[j+4]*d[d.columns[28]])/sum(d[d.columns[28]]) \n",
    "        f = sum(dconc1[j+5]*d[d.columns[28]])/sum(d[d.columns[28]]) \n",
    "        th = [a,b,c,dr,e,f]\n",
    "        new_df[new_df.columns[i]]= th # add the global concordance as a new column\n",
    "        i = i+1\n",
    "    return new_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85cec1c2",
   "metadata": {},
   "source": [
    "### Degree of credibility"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4f31262",
   "metadata": {},
   "source": [
    "The degree of credibility evaluates if the assumption that a scenario outperforms a profile is plausible and to what extent.\n",
    "\n",
    "The degree of credibility is calculated thanks to :\n",
    "- the global concordance of each scenario with each reference profile $C(a_i,b_k)$ named `dgconca`\n",
    "- the discordance matrix, separated in two DataFrames `ddiscoa` and `ddiscob`\n",
    "\n",
    "The objective is, for each scenario, follow these steps : \n",
    "\n",
    "If for all the criteria $j$,   $D_j(a_i,b_k) \\le C(a_i,b_k)$:\n",
    "<center>\n",
    "\n",
    "$ \\delta(a_i,b_k) = C(a_i,b_k) $\n",
    "\n",
    "</center>\n",
    "\n",
    "Else : \n",
    "\n",
    "<center>\n",
    "\n",
    "$ \\delta(a_i,b_k) = C(a_i,b_k) * \\prod_{j \\in J } \\frac{(1-D_j(a_i,b_k))}{(1-C(a_i,b_k))} $\n",
    "\n",
    "</center>\n",
    "\n",
    "*With J : all the criteria for whom  $D_j(a_i,b_k) \\ge C(a_i,b_k)$*\n",
    "\n",
    "The following function should be run 2 times : \n",
    "- Once considering the comparaison of performance with reference profiles $(a_i,b_k)$\n",
    "    - input : `dgconca` : the global performance  $C(a_i,b_k) $ and `ddiscoa` : the discordance :  $D_j(a_i,b_k) $\n",
    "    - output : `dcreda`: the credibility $ \\delta(a_i,b_k)$ <br>\n",
    "    \n",
    "\n",
    "- Once considering the comparaison of reference profiles with performances $(b_k,a_i)$\n",
    "    - input : `dgconcb` : the global performance  $C(b_k,a_i) $ and `ddiscoa` : the discordance :  $D_j(b_k,a_i) $\n",
    "    - output : `dcredb` the credibility $ \\delta(b_k,a_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d1d2f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def credibility(dgconc, ddisc):\n",
    "    #initialization\n",
    "    dcred = pd.DataFrame(index=['b0', 'b1', 'b2', 'b3', 'b4', 'b5'], columns=['S1.1','S1.2','S1.3','S1.4','S2.1','S2.2','S2.3','S2.4','S3.1','S3.2','S3.3','S3.4','S4.1','S4.2','S4.3','S4.4','S5.1','S5.2','S5.3','S5.4','S6.1','S6.2','S6.3','S6.4','S7.1','S7.2','S7.3','S7.4']) \n",
    "    for j in range(0, len(ddisc.columns),6): #for each scenario sc, 6 columns       \n",
    "        sc = int(j/6)                        #scenario.index\n",
    "        dc = [0, 0, 0, 0, 0, 0]\n",
    "        for pr in range(len(dcred.index)):    #for each profil\n",
    "            #case 1: Dj <= C\n",
    "            verif = 0\n",
    "            for c in ddisc.index:           \n",
    "                if  ddisc[j+pr][c] > dgconc[dgconc.columns[sc]][pr]:           \n",
    "                    verif = verif + 1\n",
    "            if verif == 0 :\n",
    "                dc[pr] = dgconc[dgconc.columns[sc]][pr]\n",
    "            #case 2: some Dj > C\n",
    "            else: \n",
    "                df_mask = ddisc[j+pr] > dgconc[dgconc.columns[sc]][pr]  \n",
    "                filtered_ddisc = ddisc[df_mask]\n",
    "                degree = (((1-filtered_ddisc[j+pr])/(1-dgconc[dgconc.columns[sc]][pr])).prod())*dgconc[dgconc.columns[sc]][pr] #le degré de credibilité du profil i et du scénario j\n",
    "        dcred[dcred.columns[sc]] = dc\n",
    "    return dcred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54e0adca",
   "metadata": {},
   "source": [
    "### Over Ranking\n",
    "\n",
    "The objective of this step is to establish preference relationships between performance and reference profiles. \n",
    "These relationships are established than the degree  of credibility determined just before and thanks to the cutting threshold $\\lambda$. \n",
    "The value of this cutting threshold can vary, and it value will be discussed later. \n",
    "\n",
    "There are 4 types of relationships that can be established between each $a_i$ and each $b_k$\n",
    "- $a_i$  `I`  $b_k$ : $a_i$  is Indifferent to  $b_k$ \n",
    "- $a_i$  `>`  $b_k$ : $a_i$  is preferred to  $b_k$ \n",
    "- $a_i$  `<`  $b_k$ : $a_i$  is not preferred to  $b_k$ \n",
    "- $a_i$  `R`  $b_k$ : $a_i$  incomparable to $b_k$ \n",
    "\n",
    "This is how this these relationship are determined : \n",
    "\n",
    "\n",
    "<center>\n",
    "<figure>\n",
    "  <img src=\"over_ranking_relations.jpg\" width=\"50%\" height=\"50%\">\n",
    "  <figcaption>Preference relationships</figcaption>\n",
    "</figure>\n",
    "</center>\n",
    "\n",
    "The function will return a Dataframe `dranking` containing all these relations between performance and reference profiles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59cd031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_ranking_relations(creda, credb, λ):\n",
    "    #initialization\n",
    "    new_df = pd.DataFrame(index=['b0', 'b1', 'b2', 'b3', 'b4', 'b5'], columns=['S1.1','S1.2','S1.3','S1.4','S2.1','S2.2','S2.3','S2.4','S3.1','S3.2','S3.3','S3.4','S4.1','S4.2','S4.3','S4.4','S5.1','S5.2','S5.3','S5.4','S6.1','S6.2','S6.3','S6.4','S7.1','S7.2','S7.3','S7.4']) \n",
    "    classementa = creda.apply(lambda x: x-λ)\n",
    "    classementb = credb.apply(lambda x: x-λ)\n",
    "    #1 if outperformance (S), 0 if not \n",
    "    classementa[classementa > 0] = 1  \n",
    "    classementa[classementa < 0] = 0  \n",
    "    classementb[classementb > 0] = 1\n",
    "    classementb[classementb < 0] = 0\n",
    "    mask = (classementa == classementb) & (classementa == 1)\n",
    "    new_df = new_df.mask(mask, \"I\")\n",
    "    mask = (classementa == classementb) & (classementa == 0)\n",
    "    new_df = new_df.mask(mask, \"R\")\n",
    "    mask = (classementb != 0) & (classementa == 0)\n",
    "    new_df = new_df.mask(mask, \"<\")\n",
    "    mask = (classementa != 0) & (classementb == 0)\n",
    "    new_df = new_df.mask(mask, \">\")\n",
    "    return new_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbc76eca",
   "metadata": {},
   "source": [
    "## Sorting\n",
    "\n",
    "The objective of the whole method is to obtain a ranking of the multiple alternatives we have for our problem. \n",
    "This method gives two types of rankings : *the pessimistic ranking and the optimistic ranking.*\n",
    "\n",
    "A median ranking can be obtained as an average of these two rankings."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07cc33b8",
   "metadata": {},
   "source": [
    "### Pessimistic sorting\n",
    "\n",
    "The following function permits to obtain the pessimistic ranking thanks to the over ranking relationships we just established.\n",
    "\n",
    "This is how the ranking works : <br>\n",
    "\n",
    "The 6 reference profiles $b0, b1, b2, b3, b4$ and $b5$ delineate 5 categories : <br>\n",
    "$C1, C2, C3, C4$ and $C5$, C5 being the best one and C1 the worse : \n",
    "\n",
    "<center>\n",
    "<figure>\n",
    "  <img src=\"pessi_sort.jpg\" width=\"10%\" height=\"10%\">\n",
    "  <figcaption><i>Pessimistic sorting<i></figcaption>\n",
    "</figure>\n",
    "</center>\n",
    "\n",
    "For each scenario, these categories will be browsed from the best to the worst ( from C5 to C1 ). \n",
    "For each reference profiles encountered the credibility $ \\delta(a_i,b_k)$ will be compared to the cutting threshold $\\lambda$ : \n",
    "- if $ \\delta(a_i,b_k) > \\lambda $ : the scenario is ranked in the category with the same number as $b_k$\n",
    "- if $ \\delta(a_i,b_k) < \\lambda $ : we continue to the next reference profile \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c83fa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pessimistic_sort(dranking,pessi):\n",
    "    for sc in dranking: \n",
    "        step = pessi[sc] \n",
    "        for pr in reversed(range(len(dranking.index))): \n",
    "            if dranking[sc][pr] == '>' or dranking[sc][pr] == 'I':\n",
    "                step[step.index[pr]] = step[step.index[pr]] +1 #classified\n",
    "                break\n",
    "        pessi[sc] = step \n",
    "    return pessi "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4da92d51",
   "metadata": {},
   "source": [
    "### Optimistic sorting\n",
    "\n",
    "The following function permits to obtain the optimistic ranking thanks to the over ranking relationships we just established.\n",
    "\n",
    "This is how the ranking works : <br>\n",
    "\n",
    "As previously 6 reference profiles delineate 5 categories, C5 being the best one and C1 the worse : \n",
    "\n",
    "<center>\n",
    "<figure>\n",
    "  <img src=\"opti_sort.jpg\" width=\"10%\" height=\"10%\">\n",
    "  <figcaption><i>Optimistic sorting<i></figcaption>\n",
    "</figure>\n",
    "</center>\n",
    "\n",
    "The difference is that for this ranking, for each scenario, these categories will be browsed from the worst to the best ( from C1 to C5 ). \n",
    "For each reference profiles encountered the over ranking relation will be analyzed : \n",
    "- if $a_i$ `<` $b_k$ : the scenario is ranked in the category with the same number as $b_k$\n",
    "- if $a_i$ `>` $b_k$, $a_i$ `R` $b_k$ or $a_i$ `I` $b_k$ : we continue to the next reference profile \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11e6b275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimistic_sort(dranking,opti):\n",
    "    for sc in dranking: \n",
    "        step = opti[sc] \n",
    "        for pr in (range(len(dranking.index))): \n",
    "            if dranking[sc][pr] == '<' or dranking[sc][pr] == 'R':\n",
    "                step[step.index[pr]] = step[step.index[pr]] +1 #classified\n",
    "                break\n",
    "        opti[sc] = step\n",
    "    return opti"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f273c69b",
   "metadata": {},
   "source": [
    "### Electre Tri method\n",
    "\n",
    "This final method permits to run all the previous methods in order to compute all the steps of the Electre Tri method. \n",
    "It takes as input : \n",
    "- `d` : the input Dataframe containing the performances, the weights, the variance, the reference profiles and the thresholds\n",
    "- `rep` : the number of times the Electre Tri method will be run, defined at the beginning of the code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd90570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def electre_tri (d,rep):\n",
    "    #initialization\n",
    "    temp = np.zeros((5,28))\n",
    "    pessi_sort = pd.DataFrame(temp, index=['C1', 'C2', 'C3', 'C4', 'C5'], columns=['S1.1','S1.2','S1.3','S1.4','S2.1','S2.2','S2.3','S2.4','S3.1','S3.2','S3.3','S3.4','S4.1','S4.2','S4.3','S4.4','S5.1','S5.2','S5.3','S5.4','S6.1','S6.2','S6.3','S6.4','S7.1','S7.2','S7.3','S7.4'])\n",
    "    opti_sort = pd.DataFrame(temp, index=['C1', 'C2', 'C3', 'C4', 'C5'], columns=['S1.1','S1.2','S1.3','S1.4','S2.1','S2.2','S2.3','S2.4','S3.1','S3.2','S3.3','S3.4','S4.1','S4.2','S4.3','S4.4','S5.1','S5.2','S5.3','S5.4','S6.1','S6.2','S6.3','S6.4','S7.1','S7.2','S7.3','S7.4'])\n",
    "    #repetitions\n",
    "    for i in range(rep) :\n",
    "        d = MCarlo(d) \n",
    "        dconca, dconcb = conce(d)\n",
    "        ddisca, ddiscb = disco(d)\n",
    "        dgconca = global_conc(d,dconca)\n",
    "        dgconcb = global_conc(d,dconcb)\n",
    "        dcreda = credibility(dgconca, ddisca)\n",
    "        dcredb = credibility(dgconcb, ddiscb)\n",
    "        dranking = over_ranking_relations(dcreda, dcredb, λ)\n",
    "        pessi_sort = pessimistic_sort(dranking,pessi_sort)\n",
    "        opti_sort = optimistic_sort(dranking,opti_sort)\n",
    "    pessi_sort = pessi_sort.apply(lambda x: (x/rep)*100) #%\n",
    "    opti_sort = opti_sort.apply(lambda x: x/rep*100) #%\n",
    "    return opti_sort, pessi_sort, dranking"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6baf0cb",
   "metadata": {},
   "source": [
    "The `electre_tri` function is run returning two DataFrames : `opti_sort` and `pessi_sort`\n",
    "\n",
    "Then two csv files are created containing the repartition of the scenarios in the categories as percentages : \n",
    "- `pessimistic_sorting.csv` for the pessimistic sorting \n",
    "- `optimistic_sorting.csv` for the optimistic sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3f57cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    S1.1  S1.2  S1.3  S1.4  S2.1  S2.2  S2.3  S2.4  S3.1  S3.2  ...  S5.3  \\\n",
      "C1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "C2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "C3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "C4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "C5   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "\n",
      "    S5.4  S6.1  S6.2  S6.3  S6.4  S7.1  S7.2  S7.3  S7.4  \n",
      "C1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "C2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "C3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "C4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "C5   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "    S1.1  S1.2  S1.3  S1.4  S2.1  S2.2  S2.3  S2.4  S3.1  S3.2  ...  S5.3  \\\n",
      "C1   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "C2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "C3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "C4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "C5   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "\n",
      "    S5.4  S6.1  S6.2  S6.3  S6.4  S7.1  S7.2  S7.3  S7.4  \n",
      "C1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "C2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "C3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "C4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "C5   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "    S1.1  S1.2  S1.3  S1.4  S2.1  S2.2  S2.3  S2.4  S3.1  S3.2  ...  S5.3  \\\n",
      "C1   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "C2   1.0   1.0   0.0   1.0   1.0   1.0   1.0   1.0   1.0   0.0  ...   1.0   \n",
      "C3   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "C4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "C5   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "\n",
      "    S5.4  S6.1  S6.2  S6.3  S6.4  S7.1  S7.2  S7.3  S7.4  \n",
      "C1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "C2   1.0   0.0   1.0   1.0   0.0   1.0   1.0   1.0   1.0  \n",
      "C3   0.0   1.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0  \n",
      "C4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "C5   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "    S1.1  S1.2  S1.3  S1.4  S2.1  S2.2  S2.3  S2.4  S3.1  S3.2  ...  S5.3  \\\n",
      "C1   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "C2   1.0   1.0   0.0   1.0   1.0   1.0   1.0   1.0   1.0   0.0  ...   1.0   \n",
      "C3   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "C4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "C5   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "\n",
      "    S5.4  S6.1  S6.2  S6.3  S6.4  S7.1  S7.2  S7.3  S7.4  \n",
      "C1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "C2   1.0   0.0   1.0   1.0   0.0   1.0   1.0   1.0   1.0  \n",
      "C3   0.0   1.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0  \n",
      "C4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "C5   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "opti_sort, pessi_sort, dranking = electre_tri (d, repet)\n",
    "\n",
    "pessi_sort.to_csv('pessimistic_sorting.csv')\n",
    "opti_sort.to_csv('optimistic_sorting.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12fa5b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "263930470851f494f0ed2879c35b57985588df20f9e529b86e97dd5eb9ddc466"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

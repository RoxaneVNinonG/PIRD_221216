{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d410e39-e0d4-4430-ba0f-fc8c59d620d0",
   "metadata": {},
   "source": [
    "# Code Python - Electre Tri "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c038ddb9",
   "metadata": {},
   "source": [
    "## Introduction to the project\n",
    "\n",
    "Multi-criteria analysis (MCA) is a decision support protocol for ranking elements by evaluating them on different criteria. It deals with a problem that has several aspects depending on the wishes of a decision maker. MCA's makes a problem more understandable, transparent, and accessible. MCA has developed well in environmental management. Renovation solutions are dynamic systems that bring together many actors, many factors with long-term applications and a lot of uncertainty. \n",
    "\n",
    "To take into account the fluctuation of the input data in environmental projects and thus to obtain results less sensitive to variations, this method is coupled with the Monte Carlo principle. Instead of using crips data, Monte Carlo allows the use of distributions for each of the data and thus allows variations in the data to be incorporated into the analysis. \n",
    "\n",
    "In this technical report, the implementation of this new procedure is presented regarding a case study. A company wanted to find a method to choose the best energy renovation scenario for a group of three buildings located in the Lyon region.  The Multi criteria Analyses used is ELECTRE Tri. The mechanisms used and the input data are presented first. Then, the different steps of the new procedures are described one by one. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c329d900",
   "metadata": {},
   "source": [
    "## Electre Tri as a multi-criteria analysis \n",
    "\n",
    "### Electre TRI method\n",
    "\n",
    "The Electre Tri method is a multi-criteria analysis which aims to sort all the alternatives in predefined categories. \n",
    "In its process, the input data for each item is compared to reference profiles that define the categories boundaries. This allows preference relationships to be established between the alternatives and the reference profiles. It can then be determined whether alternative A is \"preferred\" or \"not preferred\" to reference profile B.\n",
    "This method results in an optimistic and pessimistic sorting of the alternatives. \n",
    "\n",
    "\n",
    "Electre Tri has many advantages. First of all, it allows, as previously defined, to compare the alternatives to profiles and to determine whether or not they belong to categories. Thus, it allows to evaluate the performance of a single alternative independently of the others. The analysis is therefore easily replicable by adding, deleting and modifying some alternatives. \n",
    "Also, this method includes thresholds, that allows situations of incomparability . This is crucial since it bypasses the compensation process. Indeed, it prevents a very poor performance in one criterion from being compensated by a very good performance in another criterion. \n",
    "\n",
    "### Electre TRI applied to the renovation decision making process\n",
    "\n",
    "#### Input data\n",
    "\n",
    "##### Criteria\n",
    "\n",
    "According to Roy, a criterion is a \"tool\" that allows to evaluate an action by a specific \"point of view\". Since these criteria will allow us to establish preference relations between many alternatives, it quality of construction is crucial. Also it is important that all the actors adhere to the choice of criteria and understand what each criterion represents, its precise definition and its evaluation method.\n",
    "\n",
    "- Their units\n",
    "- Their weights\n",
    "\n",
    "Criteria should be diversified, precise but not redundant to avoid assessing the same element twice. Thus, the assessment methods for each of the criteria should be precisely described so that the same data is not used to assess different criteria. A criterion can have a direction of preference that can be either increasing or decreasing.\n",
    "\n",
    "*In order to cover all aspects of the project, 4 categories of criteria are defined: economic, social, technical and environmental where several criteria are formulated. For this project, a total of 16 criteria are finally used.*\n",
    "\n",
    " ##### Scenarios\n",
    "\n",
    "The method should show which type of renovation best fits the building and the decision makers's objectives. In order to make the method undestandable, the actions to be compared represent the different renovation possibilities that exist and the method gives the performance of each scenario regarding the others. \n",
    "\n",
    "The energy renovation of a building affects several areas and in each of these areas there are several alternatives. Renovation scenarios are formed with coherent elementary actions. Families of scenarios are formed according to the different possible alternatives in each field.\n",
    "\n",
    "*In the project, seven areas have been identified. For each of these areas, different alternatives are developed to obtain a total of 24 basic renovation actions. From the elementary actions, Thus, 28 renovation solutions are identified in total with 7 groups, first renovation solution being the one where no changes are made.*\n",
    "\n",
    "\n",
    " ##### Performance Matrix \n",
    " \n",
    "Each alternative are evaluated regarding each criterion previously established. The evaluation of the performance $a$ of the alternative $i$ regarding the criterion $j$ will be noted $u_j(a_i)$.\n",
    "In the performance matrix, each column correspond to an alternative and each line to a criterion.\n",
    "\n",
    "In a case of a criterion with an increasing preference direction, the higher the evaluation of the alternative on this criterion $u_j(a_i)$, the better the alternative performs on this criterion. Conversely, for a criterion with a decreasing performance direction, the lower the evaluation of the alternative on this criterion $u_j(a_i)$, the lower the performance of this alternative on this criterion. \n",
    "\n",
    "In order to unify the calculations and not to have to differentiate between the two cases described above, the performance values in the criteria with a decreasing preference direction will be multiplied by \"-1\". Thus, these criteria will also get an increasing performance direction. \n",
    "\n",
    "*To sum up, in this project 28 scenarios will be evaluated thanks to 16 criteria.* \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fde24ef1",
   "metadata": {},
   "source": [
    "## Uncertainty on the performances\n",
    "\n",
    "The process of filling in the performance matrix is often complicated. It is necessary to find the values for each scenario for each criterion. This value is a fixed number representing the performance of the scenario against a criterion. Each alternative does not have the same level of knowledge or application to provide reliable and accurate data. In the Electre Tri method, the data is compared to the reference profile and this difference is important in the ranking of the alternatives. A modification in the input data will have an impact in the results. \n",
    "\n",
    "In order to obtain more robust data, another parameter is integrated into the method, **the uncertainty of the data**. Instead of treating the method to a data table, the method is applied to a distribution table. **Each data is represented by its distribution**, its uncertainty. Using the Monte Carlo method, Electre Tri is applied to the distribution to obtain a distribution of each scenario into categories. \n",
    "\n",
    "*In the project, the data are represented by normal distributions. Each criteria has an associated variance. This variance quantifies the uncertainty of the data.*\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "482184b9",
   "metadata": {},
   "source": [
    "### Python environment\n",
    "\n",
    "The code is developed with the library Pandas, Numpy and Math. The input data are imported from a csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfcdcf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random, vstack, empty\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f512a50",
   "metadata": {},
   "source": [
    "### Import of data from csv file as a Pandas Dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2d03a3f",
   "metadata": {},
   "source": [
    "The input of the whole analysis is a `csv.file` made of 16 lines and 39 columns.\n",
    "\n",
    "The 16 lines correponds to 16 criteria defined earlier. \n",
    "The indices of the lines are therefore the names of the criteria: <br>\n",
    "`g1.1, g1.2, g1.3, g1.4, g1.5, g2.1, g2.2, g2.3, g2.4, g3.1, g3.2, g3.3, g3.4, g4.1, g4.2, g4.3, g4.4, g5.1, g5.2, g5.3`.\n",
    "\n",
    "The columns contain the following informations : \n",
    "- The **mean value of the performance** of each scenario regarding each criteria (columns 0 to 27) <br>\n",
    "Names of the columns : `'S1.1','S1.2','S1.3','S1.4','S2.1','S2.2','S2.3','S2.4','S3.1','S3.2','S3.3','S3.4','S4.1',`\n",
    "`'S4.2','S4.3','S4.4','S5.1','S5.2','S5.3','S5.4','S6.1','S6.2','S6.3','S6.4','S7.1','S7.2',`\n",
    "`'S7.3','S7.4'`\n",
    "- The **weight** of each criteria (column 28) <br>\n",
    "Name of the column : `Weights`\n",
    "- The **variance** of each criteria (column 29) <br>\n",
    "Name of the column : `Var`\n",
    "- The **6 reference profiles** : $b0, b1, b2, b3, b4$ and $b5$ (columns 30 to 35) <br>\n",
    "Names of the columns : `b0`, `b1`,`b2`, `b3`, `b4` and `b5`\n",
    "- The **3 thresholds** : $q$ (the indifference threshold), $p$ (the preference threshold), $v$ (the veto threshold) (columns 36 to 38) <br>\n",
    "Names of the columns : `q`, `p` and `v`\n",
    "\n",
    "\n",
    "It is imported as a dataframe `d`.<br>\n",
    "Two others parameters are also defined : \n",
    "- `λ` : the **cut-off threshold**\n",
    "- `repetition` : the **number of repetition** of the Electre Tri method desired\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f6003b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Input_data_Parameters.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m d \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mInput_data_Parameters.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m λ \u001b[39m=\u001b[39m \u001b[39m0.75\u001b[39m\n\u001b[0;32m      3\u001b[0m repetition: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m     f,\n\u001b[0;32m   1219\u001b[0m     mode,\n\u001b[0;32m   1220\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1221\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1222\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1223\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1224\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1225\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1226\u001b[0m )\n\u001b[0;32m   1227\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    790\u001b[0m             handle,\n\u001b[0;32m    791\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    792\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    793\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    794\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    795\u001b[0m         )\n\u001b[0;32m    796\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Input_data_Parameters.csv'"
     ]
    }
   ],
   "source": [
    "d = pd.read_csv('Input_data_Parameters.csv')\n",
    "λ = 0.75\n",
    "repetition: int = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e703acc6",
   "metadata": {},
   "source": [
    "### Monte Carlo Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "126e492b",
   "metadata": {},
   "source": [
    "#### How does it works ###\n",
    "Our hypothesis is to use the **Monte Carlo method** to obtain data sets from distributions and use those data sets in the Electre Tri procedure. \n",
    "\n",
    "Monte-Carlo simulation is used in complex systems in order to estimate some operations by using random sample and statistical modeling. \n",
    "1. Pick a value from Probability Distribution Functions\n",
    "2. Run the calculation multiple times: Electre Tri in our case\n",
    "3. Obtain a set of results to be analyzed \n",
    "\n",
    "The first step involve to be given Probability Distribution Functions as inputs. For our study, all the values will be represented as normal distributions. To descrive these distributions 2 parameters are needed : \n",
    "- the mean value : `m`\n",
    "- the variance : `variance`\n",
    "\n",
    "These values are given in the `d` DataFrame given as input of the code. \n",
    "\n",
    "The following function allows to :\n",
    "1. Thanks to the variance and mean value for each performance : create the Normal Distribution\n",
    "2. Pick a random value in each of it\n",
    "3. Return a DataFrame called `ndata` with the random values picked \n",
    "\n",
    "*The DataFrame returned will also contain all the parameters initially present in the `data` DataFrame.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73a5cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MC(data):\n",
    "    \"\"\"\n",
    "    Build a new performance matrix from the distribution\n",
    "    with m : mean value and v : variance per criterion\n",
    "    :param data: Data Frame with input data and parameters\n",
    "    :return: ndata: Data frame with the new performance Data Frame with random value picked\n",
    "     in the distribution\n",
    "    \"\"\"\n",
    "    ndata = data.copy()\n",
    "    variance = ndata['VAR'].values  # general variance located in the column \"VAR\"\n",
    "    m = ndata.iloc[:, 0:28].values  # for each scenario : columns 0 to 27\n",
    "    v = np.abs(m * variance[:, np.newaxis])  # variance v of the performance matrix\n",
    "    perf = np.random.normal(m, v)  # random value in the normal distribution\n",
    "    ndata.iloc[:, 0:28] = perf\n",
    "    return ndata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "590af63e",
   "metadata": {},
   "source": [
    "### Partial concordance\n",
    "\n",
    "The partial concordance refers to the degree of concordance, i.e. agreement between the evaluations of pairs of alternatives and reference profiles.In other words, it evaluates how well each option performs relative to the others with respect to the set of criteria. \n",
    "\n",
    "This function take as input the `d` DataFrame containig all the performances as well as all the others parameters and input of the method, but only the performances, the reference profiles, and the thresholds will be used.\n",
    "\n",
    "The objective is to calculate, regarding each criteria $j$ the concordance between each pair of alternative $a_i$ and reference profiles $b_k$ and in both ways: \n",
    "- The concordance $C_j(a_i,b_k)$\n",
    "- The concordance $C_j(b_k,a_i)$ <br>\n",
    "\n",
    "*for $i$ the scenarios, $k$ the reference profiles and $j$ the criteria*\n",
    "\n",
    "The following schema shows how the value of the corcordance is determined : \n",
    "\n",
    "<center>\n",
    "<figure>\n",
    "  <img src=\"concordance.jpg\" width=\"50%\" height=\"50%\">\n",
    "</figure>\n",
    "</center>\n",
    "\n",
    "*with : <br>*\n",
    "- *$u_j(a_i)$ : value of the performance of the scenario $i$ in the criterion $j$*\n",
    "- *$u_j(b_k)$ : value of the reference profile $k$ in the criterion $j$*\n",
    "\n",
    "The difference between the performance of an alternative $u_j(a_i)$ and the performance of a reference profile $u_j(b_k)$ regarding the criterion $j$ is calculated. This difference is then compared to the three thresholds $q_j, p_j, v_j$, respectively the indifference threshold, the preference threshold and the veto threshold. <br>\n",
    "\n",
    "It can be therefore interpreted as follow : <br>\n",
    "If the difference is lower than the indifference threshold $q_j$, the partial concordance will be equal to 1 since it corresponds to the acceptance of the assertion \"$a_i$ is at least as good as $b_k$\". \n",
    "On the other hand, if this difference is higher than the preference threshold $p_j$, the partial concordance would be equal to zero meaning that the assertion \"$a_i$ is at least as good as $b_k$\" is not concordant.\n",
    "\n",
    "Thus, here is how the two types of concordance can be calculated in the function: <br>\n",
    "<center>\n",
    "\n",
    "$C_j(a_i,b_k) = u_j(a_i)-u_j(b_j)+p_j/p_j-q_j$<br>\n",
    "$C_j(b_k,a_i) = u_j(b_j)-u_j(a_i)+p_j/p_j-q_j$<br>\n",
    "\n",
    "</center>\n",
    "\n",
    "*with : <br>*\n",
    "- *$u_j(a_i)$ : value of the performance of the scenario $i$ in the criterion $j$*\n",
    "- *$u_j(b_k)$ : value of the reference profile $k$ in the criterion $j$*\n",
    "- *$p_j$ : the preference threshold of the criterion $j$* \n",
    "- *$q_j$ : the indiference threshold of the criterion $j$*\n",
    "\n",
    "If the value of the concordance is higher than one it is replaced by `1`, and if it is smaller than zero it is replaced by `0`. \n",
    "\n",
    "Finally, the function returns two DataFrames : \n",
    "- `dconca` : The concordance between the performances and the reference profiles $C_k(a_i,b_j)$\n",
    "- `dconcb` : The concordance between the reference profiles and the performances $C_k(b_j,a_i)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2d4985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conc(data):\n",
    "    \"\"\"\n",
    "    Calculates the concordance coefficient between a performance and a profile\n",
    "\n",
    "    :param data: new performance Data Frame and original parameters\n",
    "    :return: new_df: DataFrame with concordance Cj(ai,bk) of each alternative ai\n",
    "    regarding each profile bk for each criterion j\n",
    "    :return: new_df2: DataFrame with concordance Cj(bk,ai) of each profile bk\n",
    "    regarding each alternative ai for each criterion j\n",
    "    \"\"\"\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df2 = pd.DataFrame()\n",
    "    for sc in data.iloc[:, 0:28]:  # for each scenario : columns 0 to 27\n",
    "        for pr in data.iloc[:, 30:36]:  # for each reference profile : columns 30 to 35\n",
    "            alpha = (data[sc] - data[pr] + data[data.columns[37]]) \\\n",
    "                    / (data[data.columns[37]] - data[data.columns[36]])\n",
    "            beta = (data[pr] - data[sc] + data[data.columns[37]]) \\\n",
    "                   / (data[data.columns[37]] - data[data.columns[36]])\n",
    "            new_df = pd.concat([new_df, alpha], axis=1, ignore_index=True)\n",
    "            new_df2 = pd.concat([new_df2, beta], axis=1, ignore_index=True)\n",
    "    new_df[new_df < 0] = 0\n",
    "    new_df[new_df > 1] = 1\n",
    "    new_df2[new_df2 < 0] = 0\n",
    "    new_df2[new_df2 > 1] = 1\n",
    "    return new_df, new_df2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b4c1f41",
   "metadata": {},
   "source": [
    "### Discordance\n",
    "\n",
    "The discordance matrix is a matrix that is used to represent the degree of discordance between pairs of alternatives and reference profiles. It is typically constructed by comparing the values of each alternative on each criterion, and determining whether the difference between the values is significant enough to cause discordance. \n",
    "\n",
    "This function take as input the `d` DataFrame containig all the performances as well as all the others parameters and input of the method, but only the performances, the reference profiles, and the thresholds will be used.\n",
    "\n",
    "The objective is to calculate, regarding each criterion $j$, the discordance between each pair of alternative $a_i$ and reference profiles $b_k$ and in both ways: \n",
    "- The discordance $D_j(a_i,b_k)$\n",
    "- The discordance $D_j(b_k,a_i)$ <br>\n",
    "*for $i$ the scenarios, $k$ the reference profiles and $j$ the criteria*\n",
    "\n",
    "The following schema shows how the value of the discordance is determined : \n",
    "\n",
    "<center>\n",
    "<figure>\n",
    "  <img src=\"discordance.jpg\" width=\"50%\" height=\"50%\">\n",
    "</figure>\n",
    "</center>\n",
    "\n",
    "It can be interpreted as follow : <br>\n",
    "If the difference is lower than the indifference threshold $q_j$, the partial concordance will be equal to 1 since it corresponds to the acceptance of the assertion \"$a_i$ is at least as good as $b_k$\". \n",
    "On the other hand, if this difference is higher than the preference threshold $p_j$, the partial concordance would be equal to zero meaning that the assertion \"$a_i$ is at least as good as $b_k$\" is not concordant. \n",
    "\n",
    "\n",
    "Thus, here is how the two types of discordance can be calculated in the function: <br>\n",
    "<center>\n",
    "\n",
    "$D_j(a_i,b_k) = u_j(b_k)-u_j(a_i)-p_j/v_j-p_j$<br>\n",
    "$D_j(b_k,a_i) = u_j(a_i)-u_j(b_k)-p_j/v_j-p_j$<br>\n",
    "\n",
    "</center>\n",
    "\n",
    "*with : <br>*\n",
    "- *$u_j(a_i)$ : value of the performance of the scenario $i$ in the criterion $j$*\n",
    "- *$u_j(b_k)$ : value of the reference profile $k$ in the criterion $j$*\n",
    "- *$p_j$ : the preference threshold of the criterion $j$* \n",
    "- *$v_j$ : the veto threshold of the criterion $j$*\n",
    "\n",
    "If the value is higher than one it is replaced by `1`, and if it is smaller dans zero it is replaced by `0`. \n",
    "\n",
    "The function takes as input the `d` Dataframe.\n",
    "Finally, the function returns two DataFrames : \n",
    "- `ddiscoa` : The discordance between the performances and the reference profiles $D_j(a_i,b_k)$\n",
    "- `ddiscob` : The discordance between the reference profiles and the performances $D_j(b_k,a_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414dda50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disco(data):\n",
    "    \"\"\"\n",
    "    Calculates the discordance coefficient between a performance and a profile\n",
    "\n",
    "    :param data: new performance Data Frame and original parameters\n",
    "    :return: new_df: DataFrame with discordance Dj(ai,bk) of each alternative ai\n",
    "    regarding each profile bk for each criterion j\n",
    "    :return: new_df2: DataFrame with discordance Dj(bk,ai) of each profile bk\n",
    "    regarding each alternative ai for each criterion j\n",
    "    \"\"\"\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df2 = pd.DataFrame()\n",
    "    for sc in data.iloc[:, 0:28]:  # for each scenario : columns 0 to 27\n",
    "        for pr in data.iloc[:, 30:36]:  # for each reference profile : columns 30 to 35\n",
    "            alpha = (data[pr] - data[sc] - data[data.columns[37]]) / (\n",
    "                    data[data.columns[38]] - data[data.columns[37]])\n",
    "            beta = (data[sc] - data[pr] - data[data.columns[37]]) / (\n",
    "                    data[data.columns[38]] - data[data.columns[37]])\n",
    "            new_df = pd.concat([new_df, alpha], axis=1, ignore_index=True)\n",
    "            new_df2 = pd.concat([new_df2, beta], axis=1, ignore_index=True)\n",
    "    new_df[new_df < 0] = 0\n",
    "    new_df[new_df > 1] = 1\n",
    "    new_df2[new_df2 < 0] = 0\n",
    "    new_df2[new_df2 > 1] = 1\n",
    "    return new_df, new_df2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e896ce2d",
   "metadata": {},
   "source": [
    "### Global concordance\n",
    "\n",
    "The aim of this step is to calculate the global concordance of each scenario regarding each criterion. In other words, it expresses to which extend the performances of $a_i$ and $b_k$ regarding all criteria are concordant with the assertion ”$a_i$ outranks $b_k$\".<br>\n",
    "It takes as input the concordance matrix and the weights for each criteria. <br>\n",
    "\n",
    "The function takes as input  :\n",
    "- the weights of each criterion, located in the `d` DataFrame, in the column 28 named `Weights`\n",
    "- the concordance matrix, separated into 2 DataFrames previously : `dconca` and `dconcb`. \n",
    "\n",
    "The objective is, for each scenario to calculate the following global concordance : \n",
    "\n",
    "<center>\n",
    "\n",
    "$C(a_i,b_k) = \\frac {\\sum_{j} C_j(a_i,b_k) * w_j}{\\sum_{j} w_j}$\n",
    "\n",
    "</center>\n",
    "\n",
    "*with i the scenarios, j the criteria and k the reference profiles*\n",
    "\n",
    "Since This function has to be used twice :\n",
    "- Once taking as input `dconca` and returning as output `dgconca` : $C(a_i,b_k)$\n",
    "- Once taking as input `dconcb` and returning as output `dgconcb` : $C(b_k,a_i)$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f4a9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gconc(data, dconc1):\n",
    "    \"\"\"\n",
    "    Calculates the global concordance\n",
    "\n",
    "    :param data: new performance Data Frame and original parameters\n",
    "    :param dconc1: concordance Data Frame\n",
    "    :return: new_df: global concordance Data Frame\n",
    "    \"\"\"\n",
    "    new_df = pd.DataFrame(index=['b0', 'b1', 'b2', 'b3', 'b4', 'b5'],\n",
    "                          columns=['S1.1', 'S1.2', 'S1.3', 'S1.4',\n",
    "                                   'S2.1', 'S2.2', 'S2.3', 'S2.4',\n",
    "                                   'S3.1', 'S3.2', 'S3.3', 'S3.4',\n",
    "                                   'S4.1', 'S4.2', 'S4.3', 'S4.4',\n",
    "                                   'S5.1', 'S5.2', 'S5.3', 'S5.4',\n",
    "                                   'S6.1', 'S6.2', 'S6.3', 'S6.4',\n",
    "                                   'S7.1', 'S7.2', 'S7.3', 'S7.4'])\n",
    "    i = 0\n",
    "    for j in range(0, len(dconc1.columns), 6):  # for each scenario : one line out of 6\n",
    "        # C(ai,bk) for the scenario for each reference profile\n",
    "        a = sum(dconc1[j] * data[data.columns[28]]) / sum(data[data.columns[28]])\n",
    "        b = sum(dconc1[j + 1] * data[data.columns[28]]) / sum(data[data.columns[28]])\n",
    "        c = sum(dconc1[j + 2] * data[data.columns[28]]) / sum(data[data.columns[28]])\n",
    "        dr = sum(dconc1[j + 3] * data[data.columns[28]]) / sum(data[data.columns[28]])\n",
    "        e = sum(dconc1[j + 4] * data[data.columns[28]]) / sum(data[data.columns[28]])\n",
    "        f = sum(dconc1[j + 5] * data[data.columns[28]]) / sum(data[data.columns[28]])\n",
    "        th = [a, b, c, dr, e, f]\n",
    "        new_df[new_df.columns[i]] = th  # add the global concordance as a new column\n",
    "        i = i + 1\n",
    "    return new_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85cec1c2",
   "metadata": {},
   "source": [
    "### Degree of credibility"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4f31262",
   "metadata": {},
   "source": [
    "The degree of credibility evaluates if the assumption that a scenario outperforms a profile is plausible and to which extent \"$a_i$ outranks $b_k$\", resulting in a value between 0 (the assumption is not plausible) and 1 (the assumption is very plausible).\n",
    "The degree of credibility evaluating the outranking of the alternative $a_i$ over the reference profile $b_k$ is noted : $ \\delta(a_i,b_k)$ (and conversely the degree of credibility evaluating the outranking of the reference profile $b_k$ over the alternative $a_i$ is noted $ \\delta(b_k,a_i)$).\n",
    "\n",
    "The degree of credibility is calculated thanks to :\n",
    "- the global concordance of each scenario with each reference profile $C(a_i,b_k)$ named `dgconca`\n",
    "- the discordance matrix, separated in two DataFrames `ddiscoa` containing the discordance  $D_j(a_i,b_k)$ and `ddiscob`containing the discordance  $D_j(b_k,a_i)$.\n",
    "\n",
    "The objective is, for each scenario, to follow these steps : \n",
    "\n",
    "If for all the criteria $j$,   $D_j(a_i,b_k) \\le C(a_i,b_k)$:\n",
    "<center>\n",
    "\n",
    "$ \\delta(a_i,b_k) = C(a_i,b_k) $\n",
    "\n",
    "</center>\n",
    "\n",
    "Else : \n",
    "\n",
    "<center>\n",
    "\n",
    "$ \\delta(a_i,b_k) = C(a_i,b_k) * \\prod_{j \\in J } \\frac{(1-D_j(a_i,b_k))}{(1-C(a_i,b_k))} $\n",
    "\n",
    "</center>\n",
    "\n",
    "*With :*\n",
    "- *J : all the criteria for whom the discordance is lower than the concordance : $D_j(a_i,b_k) \\ge C(a_i,b_k)$*\n",
    "- *$C(a_i,b_k)$ : the global concordance of the alternitive $a_i$ with the reference profile $b_k$*\n",
    "- *$D(a_i,b_k)$ : the global discordance of the alternitive $a_i$ with the reference profile $b_k$*\n",
    "\n",
    "In order to better understand the steps of this calculation the degree of credibility is calculated as follows: \n",
    "-  if within the criteria, none of them is discordant, the degree of credibility is equal to the global concordance : $ \\delta(a_i,b_k) = C(a_i,b_k)  $ \n",
    "- if one of them is discordant (equal to one), that means that it is above the veto threshold, the degree of credibility if equal to zero : $ \\delta(a_i,b_k) = 0$\n",
    "- finally, if some criteria are lower than $1$ but higher that the concordance, the degree of credibility is lower by these effects, the calculation is therefore developed in the formula above.\n",
    "\n",
    "In other words, the degree of credibility is the global concordance weakened by the eventual veto effects that can be found in the partial discordance. \n",
    "\n",
    "Since the degree of credibility must be calculated comparing the performance with the reference profiles but also comparing the reference profiles with the performance, thus the following function should be run 2 times : \n",
    "- Once considering the comparaison of performance with reference profiles $(a_i,b_k)$\n",
    "    - input : `dgconca` : the global performance  $C(a_i,b_k) $ and `ddiscoa` : the discordance :  $D_j(a_i,b_k) $\n",
    "    - output : `dcreda`: the credibility $ \\delta(a_i,b_k)$ <br>\n",
    "    \n",
    "\n",
    "- Once considering the comparaison of reference profiles with performances $(b_k,a_i)$\n",
    "    - input : `dgconcb` : the global performance  $C(b_k,a_i) $ and `ddiscoa` : the discordance :  $D_j(b_k,a_i) $\n",
    "    - output : `dcredb` the credibility $ \\delta(b_k,a_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1d2f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def credibility(dgconc, ddisc):\n",
    "    \"\"\"\n",
    "    Calculates the credibility degree\n",
    "\n",
    "    :param dgconc: Global concordance Data Frame\n",
    "    :param ddisc: Discordance Data Frame\n",
    "    :return: dcred: Credibility degree Data Frame\n",
    "    \"\"\"\n",
    "    # initialization\n",
    "    dcred = pd.DataFrame(index=['b0', 'b1', 'b2', 'b3', 'b4', 'b5'],\n",
    "                         columns=['S1.1', 'S1.2', 'S1.3', 'S1.4',\n",
    "                                  'S2.1', 'S2.2', 'S2.3', 'S2.4',\n",
    "                                  'S3.1', 'S3.2', 'S3.3', 'S3.4',\n",
    "                                  'S4.1', 'S4.2', 'S4.3', 'S4.4',\n",
    "                                  'S5.1', 'S5.2', 'S5.3', 'S5.4',\n",
    "                                  'S6.1', 'S6.2', 'S6.3', 'S6.4',\n",
    "                                  'S7.1', 'S7.2', 'S7.3', 'S7.4'])\n",
    "    for j in range(0, len(ddisc.columns), 6):\n",
    "        sc = int(j / 6)\n",
    "        degree = [0, 0, 0, 0, 0, 0]\n",
    "        for pr in range(len(dcred.index)):\n",
    "            # verification if all Dj < C\n",
    "            verif = sum(ddisc[j + pr][c] > dgconc[dgconc.columns[sc]][pr]\n",
    "                        for c in ddisc.index)\n",
    "            # case 1\n",
    "            if verif == 0:\n",
    "                degree[pr] = dgconc[dgconc.columns[sc]][pr]\n",
    "            # case 2\n",
    "            else:\n",
    "                degree[pr] = (((1 - ddisc[j + pr][ddisc[j + pr]\n",
    "                                                  > dgconc[dgconc.columns[sc]][pr]])\n",
    "                               / (1 - dgconc[dgconc.columns[sc]][pr])).prod()) * dgconc[dgconc.columns[sc]][pr]\n",
    "        dcred[dcred.columns[sc]] = degree\n",
    "    return dcred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54e0adca",
   "metadata": {},
   "source": [
    "### Over Ranking\n",
    "\n",
    "The objective of this step is to establish preference relationships between performance and reference profiles. \n",
    "These relationships are established than the degree  of credibility determined just before and thanks to the cutting threshold $\\lambda$. \n",
    "The value of this cutting threshold can vary, and it value will be discussed later. \n",
    "\n",
    "There are 4 types of relationships that can be established between each $a_i$ and each $b_k$\n",
    "- $a_i$  `I`  $b_k$ : $a_i$  is Indifferent to  $b_k$ \n",
    "- $a_i$  `>`  $b_k$ : $a_i$  is preferred to  $b_k$ \n",
    "- $a_i$  `<`  $b_k$ : $a_i$  is not preferred to  $b_k$ \n",
    "- $a_i$  `R`  $b_k$ : $a_i$  incomparable to $b_k$ \n",
    "\n",
    "This is how this these relationship are determined : \n",
    "\n",
    "\n",
    "<center>\n",
    "<figure>\n",
    "  <img src=\"over_ranking_relations.jpg\" width=\"50%\" height=\"50%\">\n",
    "  <figcaption>Preference relationships</figcaption>\n",
    "</figure>\n",
    "</center>\n",
    "\n",
    "The function will return a Dataframe `dranking` containing all these relations between performance and reference profiles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cd031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_ranking_relations(cred1, cred2, param):\n",
    "    \"\"\"\n",
    "    Calculates the relations between each alternative and each profile\n",
    "\n",
    "    :param cred1: Credibility degree Data Frame of the alternatives regarding\n",
    "    each profile\n",
    "    :param cred2: Credibility degree Data Frame of the profiles regarding\n",
    "    each alternative\n",
    "    :param param: Cut-off threshold\n",
    "    :return: new_df: Data Frame with the relation of each alternative regarding\n",
    "    each profile\n",
    "    \"\"\"\n",
    "    # initialization\n",
    "    new_df = pd.DataFrame(index=['b0', 'b1', 'b2', 'b3', 'b4', 'b5'],\n",
    "                          columns=['S1.1', 'S1.2', 'S1.3', 'S1.4',\n",
    "                                   'S2.1', 'S2.2', 'S2.3', 'S2.4',\n",
    "                                   'S3.1', 'S3.2', 'S3.3', 'S3.4',\n",
    "                                   'S4.1', 'S4.2', 'S4.3', 'S4.4',\n",
    "                                   'S5.1', 'S5.2', 'S5.3', 'S5.4',\n",
    "                                   'S6.1', 'S6.2', 'S6.3', 'S6.4',\n",
    "                                   'S7.1', 'S7.2', 'S7.3', 'S7.4'])\n",
    "    classementa = cred1.apply(lambda x: x - param)\n",
    "    classementb = cred2.apply(lambda x: x - param)\n",
    "    # 1 if outperform (S), 0 if not\n",
    "    classementa[classementa > 0] = 1\n",
    "    classementa[classementa < 0] = 0\n",
    "    classementb[classementb > 0] = 1\n",
    "    classementb[classementb < 0] = 0\n",
    "    mask = (classementa == classementb) & (classementa == 1)\n",
    "    new_df = new_df.mask(mask, \"I\")\n",
    "    mask = (classementa == classementb) & (classementa == 0)\n",
    "    new_df = new_df.mask(mask, \"R\")\n",
    "    mask = (classementb != 0) & (classementa == 0)\n",
    "    new_df = new_df.mask(mask, \"<\")\n",
    "    mask = (classementa != 0) & (classementb == 0)\n",
    "    new_df = new_df.mask(mask, \">\")\n",
    "    return new_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbc76eca",
   "metadata": {},
   "source": [
    "## Sorting\n",
    "\n",
    "The relations previously established allow to reach the final goal of the method, i.e. to assign to each alternative a category. \n",
    "Two sorting procedures are performed: optimistic and pessimistic sorting. The major difference between the two is that the pessimistic sort \"pushes the alternative down\" starting from the best category, while the optimistic sort \"pushes the alternative up\" starting from the worst category. \n",
    "\n",
    "A median ranking can be obtained as an average of these two rankings."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07cc33b8",
   "metadata": {},
   "source": [
    "### Pessimistic sorting\n",
    "\n",
    "The following function permits to obtain the pessimistic sorting thanks to the over ranking relationships we just established. The objective is to place each scenario in one of the 5 predefined categories. This type of sorting \"pushes the action down\". \n",
    "\n",
    "This is how the ranking works : <br>\n",
    "\n",
    "The 6 reference profiles $b0, b1, b2, b3, b4$ and $b5$ delineate 5 categories : <br>\n",
    "$C1, C2, C3, C4$ and $C5$, C5 being the best one and C1 the worse : \n",
    "\n",
    "<center>\n",
    "<figure>\n",
    "  <img src=\"pessi_sort.jpg\" width=\"10%\" height=\"10%\">\n",
    "  <figcaption><i>Pessimistic sorting<i></figcaption>\n",
    "</figure>\n",
    "</center>\n",
    "\n",
    "For each scenario, these categories will be browsed from the best to the worst ( from C5 to C1 ). \n",
    "For each reference profiles encountered the credibility $ \\delta(a_i,b_k)$ will be compared to the cutting threshold $\\lambda$ : \n",
    "- if $ \\delta(a_i,b_k) > \\lambda $ : the scenario is ranked in the category with the same number as $b_k$\n",
    "- if $ \\delta(a_i,b_k) < \\lambda $ : we continue to the next reference profile \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c83fa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pessimistic_sort(ranking, mpessi):\n",
    "    \"\"\"\n",
    "    Builds the pessimistic sorting\n",
    "\n",
    "    :param ranking: Data Frame with the relation of each alternative regarding\n",
    "    each profile\n",
    "    :param mpessi: Data Frame storing the pessimist ranking of each alternative\n",
    "    :return: mpessi: Updates of the Data Frame storing the pessismist sorting\n",
    "    of alternatives\n",
    "    \"\"\"\n",
    "    for sc in ranking:\n",
    "        step = mpessi[sc]\n",
    "        for pr in reversed(range(len(ranking.index))):\n",
    "            if ranking[sc][pr] == '>' or ranking[sc][pr] == 'I':\n",
    "                step[step.index[pr]] = step[step.index[pr]] + 1  # classified\n",
    "                break\n",
    "        mpessi[sc] = step\n",
    "    return mpessi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4da92d51",
   "metadata": {},
   "source": [
    "### Optimistic sorting\n",
    "\n",
    "The following function permits to obtain the optimistic ranking thanks to the over ranking relationships we just established.\n",
    "\n",
    "This is how the ranking works : <br>\n",
    "\n",
    "As previously 6 reference profiles delineate 5 categories, C5 being the best one and C1 the worse : \n",
    "\n",
    "<center>\n",
    "<figure>\n",
    "  <img src=\"opti_sort.jpg\" width=\"10%\" height=\"10%\">\n",
    "  <figcaption><i>Optimistic sorting<i></figcaption>\n",
    "</figure>\n",
    "</center>\n",
    "\n",
    "The difference is that for this ranking, for each scenario, these categories will be browsed from the worst to the best ( from C1 to C5 ). \n",
    "For each reference profiles encountered the over ranking relation will be analyzed : \n",
    "- if $a_i$ `<` $b_k$ : the scenario is ranked in the category with the same number as $b_k$\n",
    "- if $a_i$ `>` $b_k$, $a_i$ `R` $b_k$ or $a_i$ `I` $b_k$ : we continue to the next reference profile \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e6b275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimistic_sort(ranking, mopti):\n",
    "    \"\"\"\n",
    "        Builds the optimistic sorting\n",
    "\n",
    "        :param ranking: Data Frame with the relation of each alternative regarding\n",
    "        each profile\n",
    "        :param mopti: Data Frame storing the optimistic sorting of each alternative\n",
    "        :return: mopti: Updates of the Data Frame storing the optimistic sorting\n",
    "        of alternatives\n",
    "        \"\"\"\n",
    "    for sc in ranking:\n",
    "        step = mopti[sc]\n",
    "        for pr in (range(len(ranking.index))):\n",
    "            if ranking[sc][pr] == '<' or ranking[sc][pr] == 'R':\n",
    "                step[step.index[pr]] = step[step.index[pr]] + 1  # classified\n",
    "                break\n",
    "        mopti[sc] = step\n",
    "    return mopti"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f273c69b",
   "metadata": {},
   "source": [
    "### Electre Tri application function\n",
    "This final method permits to run all the previous methods in order to compute all the steps of the Electre Tri method. \n",
    "\n",
    "First of all, it takes as input : \n",
    "- `data` : the input Dataframe containing the performances, the weights, the variance, the reference profiles and the thresholds\n",
    "- `rep` : the number of times the Electre Tri method will be run, defined at the beginning of the code\n",
    "\n",
    "It creates two data frames :\n",
    "- `pessi_sort` : it allows to keep in memory the pessimistic ranking obtained at each iteration of the method\n",
    "- `opti_sort` : it allows to keep in memory the optimistic ranking obtained at each iteration of the method\n",
    "\n",
    "They are both build in the same way : <br>\n",
    "They are made of 5 lines (corresponding to the 5 categories) and 28 columns (corresponding to the 28 scenarios).\n",
    "Here are the `index` names : <br>\n",
    "`'C1', 'C2', 'C3', 'C4', 'C5'` <br>\n",
    "Here are the `columns` names : <br>\n",
    "`'S1.1','S1.2','S1.3','S1.4','S2.1','S2.2','S2.3','S2.4','S3.1','S3.2','S3.3','S3.4','S4.1',`\n",
    "`'S4.2','S4.3','S4.4','S5.1','S5.2','S5.3','S5.4','S6.1','S6.2','S6.3','S6.4','S7.1','S7.2',`\n",
    "`'S7.3','S7.4'` <br>\n",
    "Initially, they are composed only of zeros .\n",
    "\n",
    "Thereafter the following functions will be executed one after the other, the number of times `rep` which was defined at the very beginning of the code : <br>\n",
    "*(note that the functions below are clearly defined and explained one by one right above their code,including detailed explanations of input and output data)*\n",
    "\n",
    "- `MCarlo` : Monte Carlo function <br>\n",
    "    Takes as input : the input dataframe `d`<br>\n",
    "    Return : the dataframe `newdata` : the mean values have been replaced by the performances  <br>\n",
    "- `conce` : Partial Concordance function <br>\n",
    "    Takes as input :  the input dataframe `newdata` <br>\n",
    "    Return : the two concordance matrix `dconca, dconcb` <br>\n",
    "- `disco` : Discordance function <br>\n",
    "    Takes as input : the input dataframe `newdata` <br>\n",
    "    Return : the two discordance dataframes `ddisca, ddiscb`<br>\n",
    "- `global_conc` : Global Concordance function <br>\n",
    "    This function is called twice : \n",
    "    - Once taking in input : the input dataframe `newdata` and the concordance dataframe `dconca` <br>\n",
    "        Return : the global concordance dataframe `dgconca`\n",
    "    - Once taking in input : the input dataframe `newdata` and the concordance dataframe `dconcb` <br>\n",
    "        Return : the global concordance dataframe`dgconcb`\n",
    "- `credibility` : Credibility Degree function <br>\n",
    "    This function is called twice : \n",
    "    - Once taking in input : the global concordance and discordance dataframes `dgconca` and `ddisca`<br>\n",
    "        Return : credibility dataframe `dcreda`\n",
    "    - Once taking in input : the global concordance and discordance dataframes `dgconcb` and `ddiscb`<br>\n",
    "        Return : credibility dataframe `dcredb`\n",
    "- `over_ranking_relations` : Over ranking function <br>\n",
    "    Takes as input : the two credibility dataframes `dcreda` and `dcredb`<br>\n",
    "    Return : the overanking dataframe `dranking` <br>\n",
    "- `optimistic_sort` : Optimistic sorting function <br>\n",
    "    Takes as input : the overanking datadrame `dranking` and the optimistic sorting dataframe obtained at the previous iteration `opti_sort` <br>\n",
    "    Return : the optimistic sorting daframe modified, i.e. with the optimistic sorting added to the previous `opti_sort`\n",
    "- `pessimistic_sort`: Pessimistic sorting function <br>\n",
    "    Takes as input : the overanking datadrame `dranking` and the pessimistic sorting dataframe `pessi_sort` <br>\n",
    "    Return : the pessimistic sorting daframe modified, i.e. with the pessimistic sorting added to the previous `pessi_sort`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd90570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Elec_tri(data, rep):\n",
    "    \"\"\"\n",
    "    Function which capitalises ELECTRE_Tri calculations and repeats them\n",
    "     a rep number of times\n",
    "\n",
    "    :param data: Input data and parameters\n",
    "    :param rep: Number of repetition\n",
    "    :return: opti_sort: Data Frame with percentage of time each alternative are classified in each\n",
    "    category within a optimistic sorting\n",
    "    :return: pessi_sort: Data Frame with percentage of time each alternative are classified in each\n",
    "     category within a pessimistic sorting\n",
    "    \"\"\"\n",
    "    pessi = np.zeros((5, 28))\n",
    "    opti = np.zeros((5, 28))\n",
    "    pessi_sort = pd.DataFrame(pessi, index=['C1', 'C2', 'C3', 'C4', 'C5'],\n",
    "                              columns=['S1.1', 'S1.2', 'S1.3', 'S1.4',\n",
    "                                       'S2.1', 'S2.2', 'S2.3', 'S2.4',\n",
    "                                       'S3.1', 'S3.2', 'S3.3', 'S3.4',\n",
    "                                       'S4.1', 'S4.2', 'S4.3', 'S4.4',\n",
    "                                       'S5.1', 'S5.2', 'S5.3', 'S5.4',\n",
    "                                       'S6.1', 'S6.2', 'S6.3', 'S6.4',\n",
    "                                       'S7.1', 'S7.2', 'S7.3', 'S7.4'])\n",
    "    opti_sort = pd.DataFrame(opti, index=['C1', 'C2', 'C3', 'C4', 'C5'],\n",
    "                             columns=['S1.1', 'S1.2', 'S1.3', 'S1.4',\n",
    "                                      'S2.1', 'S2.2', 'S2.3', 'S2.4',\n",
    "                                      'S3.1', 'S3.2', 'S3.3', 'S3.4',\n",
    "                                      'S4.1', 'S4.2', 'S4.3', 'S4.4',\n",
    "                                      'S5.1', 'S5.2', 'S5.3', 'S5.4',\n",
    "                                      'S6.1', 'S6.2', 'S6.3', 'S6.4',\n",
    "                                      'S7.1', 'S7.2', 'S7.3', 'S7.4'])\n",
    "    # repetitions\n",
    "    for i in range(rep):\n",
    "        newdata = MC(data)\n",
    "        dconca, dconcb = conc(newdata)\n",
    "        ddisca, ddiscb = disco(newdata)\n",
    "        dgconca = gconc(newdata, dconca)\n",
    "        dgconcb = gconc(newdata, dconcb)\n",
    "        dcreda = credibility(dgconca, ddisca)\n",
    "        dcredb = credibility(dgconcb, ddiscb)\n",
    "        dranking = over_ranking_relations(dcreda, dcredb, λ)\n",
    "        opti_sort = optimistic_sort(dranking, opti_sort)\n",
    "        pessi_sort = pessimistic_sort(dranking, pessi_sort)\n",
    "    pessi_sort = pessi_sort.apply(lambda x: (x / rep) * 100)  # %\n",
    "    opti_sort = opti_sort.apply(lambda x: x / rep * 100)  # %\n",
    "    return opti_sort, pessi_sort"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6baf0cb",
   "metadata": {},
   "source": [
    "The `electre_tri` function is run returning two DataFrames : `o_sorting` and `p_sorting`. \n",
    "\n",
    "Then two csv files are created containing the repartition of the scenarios in the categories as percentages : \n",
    "- `pessimistic_sorting.csv` for the pessimistic sorting \n",
    "- `optimistic_sorting.csv` for the optimistic sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f57cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimistic sorting of the scenarios is:\n",
      "     S1.1   S1.2   S1.3   S1.4   S2.1   S2.2   S2.3   S2.4   S3.1   S3.2  ...  \\\n",
      "C1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
      "C2  100.0    0.0    0.0  100.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
      "C3    0.0  100.0  100.0    0.0  100.0    0.0    0.0    0.0  100.0    0.0  ...   \n",
      "C4    0.0    0.0    0.0    0.0    0.0  100.0  100.0  100.0    0.0  100.0  ...   \n",
      "C5    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
      "\n",
      "     S5.3   S5.4   S6.1   S6.2   S6.3   S6.4   S7.1   S7.2   S7.3   S7.4  \n",
      "C1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
      "C2  100.0  100.0    0.0    0.0  100.0    0.0  100.0  100.0  100.0  100.0  \n",
      "C3    0.0    0.0    0.0  100.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
      "C4    0.0    0.0  100.0    0.0    0.0  100.0    0.0    0.0    0.0    0.0  \n",
      "C5    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "The pessimistic sorting of the scenarios is:\n",
      "     S1.1   S1.2   S1.3   S1.4   S2.1   S2.2   S2.3   S2.4   S3.1   S3.2  ...  \\\n",
      "C1  100.0    0.0    0.0  100.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
      "C2    0.0  100.0  100.0    0.0  100.0    0.0    0.0    0.0  100.0    0.0  ...   \n",
      "C3    0.0    0.0    0.0    0.0    0.0  100.0  100.0  100.0    0.0  100.0  ...   \n",
      "C4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
      "C5    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
      "\n",
      "     S5.3   S5.4   S6.1   S6.2   S6.3   S6.4   S7.1   S7.2   S7.3   S7.4  \n",
      "C1  100.0  100.0    0.0    0.0  100.0    0.0  100.0  100.0  100.0  100.0  \n",
      "C2    0.0    0.0    0.0  100.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
      "C3    0.0    0.0  100.0    0.0    0.0  100.0    0.0    0.0    0.0    0.0  \n",
      "C4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
      "C5    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "o_sorting, p_sorting = Elec_tri(d, repetition)\n",
    "\n",
    "# p_sorting.to_csv('pessimistic_sorting.csv')\n",
    "# o_sorting.to_csv('optimistic_sorting.csv')\n",
    "\n",
    "print(\"The optimistic sorting of the scenarios is:\")\n",
    "print(o_sorting)\n",
    "print(\"The pessimistic sorting of the scenarios is:\")\n",
    "print(p_sorting)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "263930470851f494f0ed2879c35b57985588df20f9e529b86e97dd5eb9ddc466"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
